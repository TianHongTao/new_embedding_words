{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function set_backend in module tensorly:\n",
      "\n",
      "set_backend(backend_name)\n",
      "    Sets the backend for TensorLy\n",
      "    \n",
      "        The backend will be set as specified and operations will used that backend\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    backend_name : {'mxnet', 'numpy', 'pytorch', 'tensorflow', 'cupy'}, default is 'numpy'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 128\n",
    "tl.set_backend('pytorch')\n",
    "help(tl.set_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467,)\n"
     ]
    }
   ],
   "source": [
    "tag = [72, 71, 84, 54, 57, 65, 64]\n",
    "Y = np.zeros(467)\n",
    "print(Y.shape)\n",
    "Y[0 : tag[0]] = 0\n",
    "Y[tag[0] : tag[0]+tag[1]] = 1\n",
    "Y[tag[0]+tag[1] : tag[0]+tag[1]+tag[2]] = 2\n",
    "Y[tag[0]+tag[1]+tag[2] : tag[0]+tag[1]+tag[2]+tag[3]] = 3\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]] = 4\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]] = 5\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]+tag[6]] = 6\n",
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "MAX_LENGTH = 53\n",
    "for i in range(0,467):\n",
    "    a = np.loadtxt('/Users/denhiroshi/Downloads/Embeding/ans_1.0_'+str(i)+'.csv',dtype=np.float64,delimiter=',')\n",
    "    a = a.transpose(1,0)\n",
    "    a = np.exp(a)\n",
    "    a = np.sum(a,axis=1)\n",
    "    a = np.log(a)\n",
    "    if a.shape[0] < MAX_LENGTH:\n",
    "        add = MAX_LENGTH - a.shape[0]\n",
    "        adds = np.zeros(add).astype(np.float64)\n",
    "        a = np.concatenate((a, adds))\n",
    "    inputs.append(a)\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = np.stack(inputs)\n",
    "mean = use.mean()         #计算平均数\n",
    "deviation = use.std()     #计算标准差\n",
    "# 标准化数据的公式: (数据值 - 平均数) / 标准差\n",
    "use = (use - mean) / deviation\n",
    "use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.fromfile('glove_WV.dat',dtype=np.float64).reshape((467,-1,200))\n",
    "position_tag = np.loadtxt('position_tag.csv',dtype=np.float64,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53, 202)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [i for i in range(53)]\n",
    "c = []\n",
    "for i in range(467):\n",
    "    position_a = (np.array(temp) - position_tag[i][0]).reshape((-1,1))\n",
    "    position_b = (np.array(temp) - position_tag[i][1]).reshape((-1,1))\n",
    "    position = np.concatenate((position_a,position_b),axis = 1)\n",
    "    c.append(np.concatenate((b[i],position),axis = 1))\n",
    "c = np.stack(c)\n",
    "b = c\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(467):\n",
    "    inputs.append((torch.from_numpy(b[i]),torch.from_numpy(use[i]),Y[i],position_tag[i].astype(np.int64)))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([141, 53]),\n",
       " torch.Size([141, 53, 202]),\n",
       " torch.Size([141]),\n",
       " torch.Size([141, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = []\n",
    "t_e = []\n",
    "t_y = []\n",
    "t_p = []\n",
    "\n",
    "for E,S,Y,pos in test:\n",
    "    t_s.append(S)\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "    t_p.append(pos)\n",
    "t_s = torch.stack(t_s)\n",
    "t_e = torch.stack(t_e)\n",
    "t_p = torch.from_numpy(np.stack(t_p))\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_s.shape, t_e.shape, t_y.shape, t_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.8226950354609929 18轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 53, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=53,    # n_filters\n",
    "                kernel_size=(1,203),      # filter size\n",
    "            ),      # output shape (16, 53, 200)\n",
    "            nn.ReLU(),    # activation\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(53,1))   # 在 2x2 空间里向下采样, output shape (16, 53, 1)\n",
    "        self.output = nn.Linear(159, 7)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, sen, x, pos):\n",
    "        torch.set_default_dtype(torch.double)\n",
    "        sen = sen.reshape((sen.shape[0],1,sen.shape[1])) # (BATCH_SIZE,1,53)\n",
    "        use = torch.bmm(sen.double(),x) # (BATCH_SIZE,1,202)\n",
    "        use = torch.sigmoid(use) # (BATCH_SIZE,1,202)\n",
    "        use = torch.softmax(use,2) # (BATCH_SIZE,1,202)\n",
    "        use = use.reshape((use.shape[0],-1,1))\n",
    "        use = torch.bmm(x,use)\n",
    "        x = torch.cat((x,use),2)\n",
    "        \n",
    "        x = x.reshape((x.shape[0],1,x.shape[1],-1)).double()\n",
    "        x = self.conv1(x.double())\n",
    "        \n",
    "        x1 = torch.zeros(x.shape)\n",
    "        x2 = torch.zeros(x.shape)\n",
    "        x3 = torch.zeros(x.shape)\n",
    "        \n",
    "        min_x1 = torch.ones(x.shape) * (-100)\n",
    "        min_x2 = torch.ones(x.shape) * (-100)\n",
    "        min_x3 = torch.ones(x.shape) * (-100)\n",
    "        \n",
    "        for i in range(pos.shape[0]):\n",
    "            x1[i, :, :pos[i][0], :]\n",
    "            min_x1[i, :, :pos[i][0], :]  = 0.0\n",
    "            x2[i, :, pos[i][0]:pos[i][1], :]  = 1.0\n",
    "            min_x2[i, :, pos[i][0]:pos[i][1], :] = 0.0\n",
    "            x3[i, :, pos[i][1]:, :] = 1.0\n",
    "            min_x3[i, :, pos[i][1]:, :] = 0.0\n",
    "            \n",
    "         # 卷积结果*mask得到分段后的卷积向量\n",
    "        x1 *= x\n",
    "        x2 *= x\n",
    "        x3 *= x\n",
    "        \n",
    "        # 将无用部分赋予最小值，避免影响maxpool操作\n",
    "        x1 += min_x1\n",
    "        x2 += min_x2\n",
    "        x3 += min_x3\n",
    "        \n",
    "        # 分段池化\n",
    "        x1 = self.maxpool(x1)\n",
    "        x2 = self.maxpool(x2)\n",
    "        x3 = self.maxpool(x3)\n",
    "        \n",
    "        # 展平\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 53, kernel_size=(1, 203), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=(53, 1), stride=(53, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (output): Linear(in_features=159, out_features=7, bias=True)\n",
      ")\n",
      "1: accuracy:0.22695035460992907 loss: 3.856832036580364 time: 0.32442283630371094\n",
      "2: accuracy:0.3900709219858156 loss: 4.334052226630342 time: 0.6754150390625\n",
      "3: accuracy:0.475177304964539 loss: 6.0353584189558855 time: 1.1260218620300293\n",
      "4: accuracy:0.524822695035461 loss: 2.514544324199227 time: 1.5120198726654053\n",
      "5: accuracy:0.5886524822695035 loss: 4.381717279379225 time: 1.8636858463287354\n",
      "6: accuracy:0.6524822695035462 loss: 3.0337188034739677 time: 2.2203409671783447\n",
      "7: accuracy:0.6595744680851063 loss: 4.124322989278649 time: 2.572683095932007\n",
      "8: accuracy:0.6879432624113475 loss: 2.119649808648928 time: 2.9193739891052246\n",
      "9: accuracy:0.6879432624113475 loss: 0.30038584932638035 time: 3.2629170417785645\n",
      "10: accuracy:0.6808510638297872 loss: 0.42145781945848687 time: 3.6501498222351074\n",
      "11: accuracy:0.75177304964539 loss: 0.13382483461249597 time: 4.055239915847778\n",
      "12: accuracy:0.7446808510638298 loss: 0.06389894734735282 time: 4.405045032501221\n",
      "13: accuracy:0.7021276595744681 loss: 1.5499651078968013 time: 4.758952856063843\n",
      "14: accuracy:0.7304964539007093 loss: 3.388622435211954 time: 5.107836961746216\n",
      "15: accuracy:0.7730496453900709 loss: 0.9257710687718698 time: 5.45285701751709\n",
      "16: accuracy:0.7446808510638298 loss: 0.02990717354251014 time: 5.791445970535278\n",
      "17: accuracy:0.7304964539007093 loss: 0.02887357504630421 time: 6.130444049835205\n",
      "18: accuracy:0.7092198581560284 loss: 0.6648601272610037 time: 6.464133024215698\n",
      "19: accuracy:0.75177304964539 loss: 0.03991385348803744 time: 6.867348909378052\n",
      "20: accuracy:0.75177304964539 loss: 0.013631109834856112 time: 7.25925874710083\n",
      "21: accuracy:0.7588652482269503 loss: 0.015761408854259727 time: 7.600921154022217\n",
      "22: accuracy:0.7588652482269503 loss: 0.02041823565756835 time: 7.955809116363525\n",
      "23: accuracy:0.7588652482269503 loss: 0.013132397222176196 time: 8.301944971084595\n",
      "24: accuracy:0.7801418439716312 loss: 0.007007661786288796 time: 8.647251844406128\n",
      "25: accuracy:0.7801418439716312 loss: 0.0027059657578039457 time: 8.990376949310303\n",
      "26: accuracy:0.7872340425531915 loss: 0.0028760288085798447 time: 9.34101390838623\n",
      "27: accuracy:0.7943262411347518 loss: 0.00769125542081389 time: 9.730501174926758\n",
      "28: accuracy:0.7943262411347518 loss: 0.005430082323656709 time: 10.095479965209961\n",
      "29: accuracy:0.8085106382978723 loss: 0.004988993205941997 time: 10.450031757354736\n",
      "30: accuracy:0.8085106382978723 loss: 0.002934602846239295 time: 10.806581974029541\n",
      "31: accuracy:0.7943262411347518 loss: 0.0019020912344391025 time: 11.153786182403564\n",
      "32: accuracy:0.8014184397163121 loss: 0.0010522345101745577 time: 11.533195972442627\n",
      "33: accuracy:0.7943262411347518 loss: 0.0016436099681026407 time: 11.933640956878662\n",
      "34: accuracy:0.7943262411347518 loss: 0.0014375544265793 time: 12.274647951126099\n",
      "35: accuracy:0.7943262411347518 loss: 0.0013990020694206707 time: 12.625715017318726\n",
      "36: accuracy:0.7943262411347518 loss: 0.0009897660480336246 time: 12.964763879776001\n",
      "37: accuracy:0.7943262411347518 loss: 0.0017133676069600082 time: 13.306535959243774\n",
      "38: accuracy:0.7943262411347518 loss: 0.0009072539802428915 time: 13.746538877487183\n",
      "39: accuracy:0.7943262411347518 loss: 0.000881859774312886 time: 14.16382884979248\n",
      "40: accuracy:0.7943262411347518 loss: 0.0009786909342289604 time: 14.556384086608887\n",
      "41: accuracy:0.7943262411347518 loss: 0.0008532184110564524 time: 14.954591035842896\n",
      "42: accuracy:0.8014184397163121 loss: 0.0008686823511617727 time: 15.386404037475586\n",
      "43: accuracy:0.8014184397163121 loss: 0.00048550397588456665 time: 15.744730949401855\n",
      "44: accuracy:0.8014184397163121 loss: 0.0006816969554010629 time: 16.10139799118042\n",
      "45: accuracy:0.8014184397163121 loss: 0.0004730152405861102 time: 16.449366092681885\n",
      "46: accuracy:0.8014184397163121 loss: 0.000660040223272367 time: 16.795036792755127\n",
      "47: accuracy:0.8014184397163121 loss: 0.0009612976275411355 time: 17.129008769989014\n",
      "48: accuracy:0.8014184397163121 loss: 0.0005346193515351213 time: 17.468894004821777\n",
      "49: accuracy:0.8014184397163121 loss: 0.0004989982663427714 time: 17.821457862854004\n",
      "50: accuracy:0.8014184397163121 loss: 0.0007221723005187451 time: 18.18228793144226\n",
      "51: accuracy:0.8014184397163121 loss: 0.000552129666697722 time: 18.546751976013184\n",
      "52: accuracy:0.8014184397163121 loss: 0.0007689421037199574 time: 18.900365114212036\n",
      "53: accuracy:0.8014184397163121 loss: 0.00048287591877961436 time: 19.36777400970459\n",
      "54: accuracy:0.8014184397163121 loss: 0.0007585285481479711 time: 19.757267951965332\n",
      "55: accuracy:0.8014184397163121 loss: 0.0006877081204054772 time: 20.17144799232483\n",
      "56: accuracy:0.8014184397163121 loss: 0.0005112561265479876 time: 20.549746990203857\n",
      "57: accuracy:0.8014184397163121 loss: 0.0005689144292576133 time: 20.943788051605225\n",
      "58: accuracy:0.8014184397163121 loss: 0.0005430393916140451 time: 21.32808804512024\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = CNN()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "start = time.time()\n",
    "for epoch in range(1,201): \n",
    "    for step, (batch_x, sen, batch_y,pos) in enumerate(loader):\n",
    "        pred = net(sen,batch_x,pos)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_s,t_e,t_p)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss} time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
