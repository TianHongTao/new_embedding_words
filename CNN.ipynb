{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function set_backend in module tensorly:\n",
      "\n",
      "set_backend(backend_name)\n",
      "    Sets the backend for TensorLy\n",
      "    \n",
      "        The backend will be set as specified and operations will used that backend\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    backend_name : {'mxnet', 'numpy', 'pytorch', 'tensorflow', 'cupy'}, default is 'numpy'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 128\n",
    "tl.set_backend('pytorch')\n",
    "help(tl.set_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467,)\n"
     ]
    }
   ],
   "source": [
    "tag = [72, 71, 84, 54, 57, 65, 64]\n",
    "Y = np.zeros(467)\n",
    "print(Y.shape)\n",
    "Y[0 : tag[0]] = 0\n",
    "Y[tag[0] : tag[0]+tag[1]] = 1\n",
    "Y[tag[0]+tag[1] : tag[0]+tag[1]+tag[2]] = 2\n",
    "Y[tag[0]+tag[1]+tag[2] : tag[0]+tag[1]+tag[2]+tag[3]] = 3\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]] = 4\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]] = 5\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]+tag[6]] = 6\n",
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "max_length = 0\n",
    "for i in range(0,467):\n",
    "    a = np.loadtxt('/Users/denhiroshi/Downloads/Embeding/ans_1.0_'+str(i)+'.csv',dtype=np.float64,delimiter=',')\n",
    "    a = a.transpose(1,0)\n",
    "    a = np.exp(a)\n",
    "    a = np.sum(a,axis=0)\n",
    "    a = np.log(a)\n",
    "    inputs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = np.stack(inputs)\n",
    "mean = use.mean()         #计算平均数\n",
    "deviation = use.std()     #计算标准差\n",
    "# 标准化数据的公式: (数据值 - 平均数) / 标准差\n",
    "use = (use - mean) / deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.fromfile('glove_WV.dat',dtype=np.float64).reshape((467,-1,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(467):\n",
    "    inputs.append((torch.from_numpy(b[i]),torch.from_numpy(use[i]),Y[i]))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([141, 467]), torch.Size([141, 53, 200]), torch.Size([141]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = []\n",
    "t_e = []\n",
    "t_y = []\n",
    "for E,S,Y in test:\n",
    "    t_s.append(S)\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "t_s = torch.stack(t_s)\n",
    "t_e = torch.stack(t_e)\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_s.shape, t_e.shape, t_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.6170212765957447 23轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 53, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=53,    # n_filters\n",
    "                kernel_size=(1,200),      # filter size\n",
    "            ),      # output shape (16, 53, 200)\n",
    "            nn.ReLU(),    # activation\n",
    "            nn.MaxPool2d(kernel_size=(53,1)),    # 在 2x2 空间里向下采样, output shape (16, 53, 1)\n",
    "        )\n",
    "        self.output = nn.Linear(53, 7)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        torch.set_default_dtype(torch.double)\n",
    "        x = x.reshape((-1,1,53,200)).double()\n",
    "        x = self.conv1(x.double())\n",
    "        x = x.view(x.size(0), -1)   # 展平\n",
    "#         x = self.out(x)\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 53, kernel_size=(1, 200), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(53, 1), stride=(53, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (output): Linear(in_features=53, out_features=7, bias=True)\n",
      ")\n",
      "1: accuracy:0.2198581560283688 loss: 1.9037755804325567 time: 0.2097330093383789\n",
      "2: accuracy:0.4397163120567376 loss: 1.549300305141994 time: 0.41186094284057617\n",
      "3: accuracy:0.5177304964539007 loss: 1.2839013002986361 time: 0.5966610908508301\n",
      "4: accuracy:0.5602836879432624 loss: 0.9303090941539431 time: 0.7908508777618408\n",
      "5: accuracy:0.5673758865248227 loss: 0.7797673715684522 time: 1.0172820091247559\n",
      "6: accuracy:0.5460992907801419 loss: 0.47803366497188804 time: 1.2342960834503174\n",
      "7: accuracy:0.5886524822695035 loss: 0.357710195641941 time: 1.4224300384521484\n",
      "8: accuracy:0.5957446808510638 loss: 0.29129630251229527 time: 1.6051998138427734\n",
      "9: accuracy:0.5815602836879432 loss: 0.16800746455333423 time: 1.7896881103515625\n",
      "10: accuracy:0.5957446808510638 loss: 0.1263754665175755 time: 1.978957176208496\n",
      "11: accuracy:0.5815602836879432 loss: 0.09401861365279093 time: 2.1616311073303223\n",
      "12: accuracy:0.6028368794326241 loss: 0.04200102244183973 time: 2.329357147216797\n",
      "13: accuracy:0.6028368794326241 loss: 0.03717533521542245 time: 2.5017638206481934\n",
      "14: accuracy:0.5815602836879432 loss: 0.02162056601657597 time: 2.666818857192993\n",
      "15: accuracy:0.5815602836879432 loss: 0.017078924968750124 time: 2.8381199836730957\n",
      "16: accuracy:0.6170212765957447 loss: 0.012450716648989753 time: 3.001620054244995\n",
      "17: accuracy:0.6099290780141844 loss: 0.010135303761446675 time: 3.174757957458496\n",
      "18: accuracy:0.6028368794326241 loss: 0.00858882920626311 time: 3.3408751487731934\n",
      "19: accuracy:0.5957446808510638 loss: 0.007950053136357691 time: 3.509399175643921\n",
      "20: accuracy:0.6028368794326241 loss: 0.006747786945153068 time: 3.6775319576263428\n",
      "21: accuracy:0.6170212765957447 loss: 0.006230457861131893 time: 3.844611883163452\n",
      "22: accuracy:0.6170212765957447 loss: 0.005424171053004611 time: 4.0149431228637695\n",
      "23: accuracy:0.6170212765957447 loss: 0.005105955827422586 time: 4.1814610958099365\n",
      "24: accuracy:0.6170212765957447 loss: 0.003890766639157198 time: 4.352792978286743\n",
      "25: accuracy:0.6170212765957447 loss: 0.004102969378263748 time: 4.5256829261779785\n",
      "26: accuracy:0.6099290780141844 loss: 0.0035591987529822572 time: 4.704207897186279\n",
      "27: accuracy:0.6028368794326241 loss: 0.0036452333504397583 time: 4.891693830490112\n",
      "28: accuracy:0.5957446808510638 loss: 0.0031940357222700515 time: 5.15188193321228\n",
      "29: accuracy:0.6028368794326241 loss: 0.0032917598688023525 time: 5.380820035934448\n",
      "30: accuracy:0.6099290780141844 loss: 0.0036195209866152146 time: 5.586226940155029\n",
      "31: accuracy:0.6099290780141844 loss: 0.002631632711239832 time: 5.758784055709839\n",
      "32: accuracy:0.6028368794326241 loss: 0.003233301269611769 time: 5.9273669719696045\n",
      "33: accuracy:0.6028368794326241 loss: 0.0024988403441371875 time: 6.108680009841919\n",
      "34: accuracy:0.6028368794326241 loss: 0.0024951736704623504 time: 6.299752950668335\n",
      "35: accuracy:0.6028368794326241 loss: 0.002486543882043733 time: 6.472193002700806\n",
      "36: accuracy:0.6028368794326241 loss: 0.0025997012609969908 time: 6.638548135757446\n",
      "37: accuracy:0.6028368794326241 loss: 0.0026105304390564832 time: 6.810322999954224\n",
      "38: accuracy:0.6028368794326241 loss: 0.0023616821897165076 time: 6.977520942687988\n",
      "39: accuracy:0.6099290780141844 loss: 0.002334912972722103 time: 7.15030312538147\n",
      "40: accuracy:0.6099290780141844 loss: 0.0019962817286687316 time: 7.319118976593018\n",
      "41: accuracy:0.6099290780141844 loss: 0.0021001706577292467 time: 7.486647129058838\n",
      "42: accuracy:0.6099290780141844 loss: 0.0018677499408692327 time: 7.658015012741089\n",
      "43: accuracy:0.6099290780141844 loss: 0.0018700300936890203 time: 7.824483871459961\n",
      "44: accuracy:0.6099290780141844 loss: 0.0020706470246128436 time: 7.99580192565918\n",
      "45: accuracy:0.6099290780141844 loss: 0.0015230608882242258 time: 8.16455602645874\n",
      "46: accuracy:0.6099290780141844 loss: 0.001673669592955778 time: 8.337237119674683\n",
      "47: accuracy:0.6099290780141844 loss: 0.0019845069504932844 time: 8.501282215118408\n",
      "48: accuracy:0.6099290780141844 loss: 0.0017676916490891234 time: 8.673743963241577\n",
      "49: accuracy:0.6028368794326241 loss: 0.0015164224487415152 time: 8.840137958526611\n",
      "50: accuracy:0.6028368794326241 loss: 0.001614356388768374 time: 9.010388135910034\n",
      "51: accuracy:0.6028368794326241 loss: 0.001736024994742318 time: 9.181500911712646\n",
      "52: accuracy:0.6028368794326241 loss: 0.0015562744338536343 time: 9.357697010040283\n",
      "53: accuracy:0.6099290780141844 loss: 0.001432912519557039 time: 9.54441499710083\n",
      "54: accuracy:0.6099290780141844 loss: 0.0014845352338639817 time: 9.724551916122437\n",
      "55: accuracy:0.6099290780141844 loss: 0.0014446770743295305 time: 9.912752866744995\n",
      "56: accuracy:0.6099290780141844 loss: 0.0015129558850744866 time: 10.084212064743042\n",
      "57: accuracy:0.6099290780141844 loss: 0.0013246143098415114 time: 10.269105911254883\n",
      "58: accuracy:0.6099290780141844 loss: 0.001098097666240548 time: 10.443453073501587\n",
      "59: accuracy:0.6099290780141844 loss: 0.001267474880694389 time: 10.664686918258667\n",
      "60: accuracy:0.6099290780141844 loss: 0.0012816933162394216 time: 10.905569076538086\n",
      "61: accuracy:0.6099290780141844 loss: 0.0011416311000742776 time: 11.154446840286255\n",
      "62: accuracy:0.6099290780141844 loss: 0.001120690352373353 time: 11.412928104400635\n",
      "63: accuracy:0.6170212765957447 loss: 0.0011517818315611654 time: 11.663465023040771\n",
      "64: accuracy:0.6170212765957447 loss: 0.0010403736979741776 time: 11.917876958847046\n",
      "65: accuracy:0.6170212765957447 loss: 0.001130199228939339 time: 12.095683813095093\n",
      "66: accuracy:0.6170212765957447 loss: 0.0010677365676661221 time: 12.294044971466064\n",
      "67: accuracy:0.6099290780141844 loss: 0.0010361161748805461 time: 12.484563112258911\n",
      "68: accuracy:0.6099290780141844 loss: 0.001103389040294684 time: 12.679903984069824\n",
      "69: accuracy:0.6099290780141844 loss: 0.0009153701790509863 time: 12.908344030380249\n",
      "70: accuracy:0.6099290780141844 loss: 0.001003532032086607 time: 13.135203838348389\n",
      "71: accuracy:0.6099290780141844 loss: 0.0009632048721270055 time: 13.336030960083008\n",
      "72: accuracy:0.6099290780141844 loss: 0.0010460786471809971 time: 13.610986948013306\n",
      "73: accuracy:0.6099290780141844 loss: 0.0009674027869487314 time: 13.794306755065918\n",
      "74: accuracy:0.6099290780141844 loss: 0.0008899088926094288 time: 14.059578895568848\n",
      "75: accuracy:0.6099290780141844 loss: 0.0008455892693202699 time: 14.34359884262085\n",
      "76: accuracy:0.6099290780141844 loss: 0.0008645470608092636 time: 14.544910907745361\n",
      "77: accuracy:0.6099290780141844 loss: 0.0009010730431887699 time: 14.80427098274231\n",
      "78: accuracy:0.6099290780141844 loss: 0.0007615323520423267 time: 14.968443870544434\n",
      "79: accuracy:0.6099290780141844 loss: 0.000817365932694823 time: 15.148891925811768\n",
      "80: accuracy:0.6099290780141844 loss: 0.0007888154981277358 time: 15.3246169090271\n",
      "81: accuracy:0.6099290780141844 loss: 0.0007539766078759946 time: 15.553432941436768\n",
      "82: accuracy:0.6099290780141844 loss: 0.0008050936309204852 time: 15.728209018707275\n",
      "83: accuracy:0.6099290780141844 loss: 0.0007933276550914263 time: 15.91172194480896\n",
      "84: accuracy:0.6099290780141844 loss: 0.000772376682808597 time: 16.078765153884888\n",
      "85: accuracy:0.6099290780141844 loss: 0.0008538585358993117 time: 16.251195907592773\n",
      "86: accuracy:0.6099290780141844 loss: 0.0007875648302616398 time: 16.415181875228882\n",
      "87: accuracy:0.6099290780141844 loss: 0.0006123041541493076 time: 16.603312969207764\n",
      "88: accuracy:0.6099290780141844 loss: 0.0007524406498069323 time: 16.78841495513916\n",
      "89: accuracy:0.6099290780141844 loss: 0.000708961001214251 time: 16.957483053207397\n",
      "90: accuracy:0.6099290780141844 loss: 0.0007673350878059284 time: 17.178584814071655\n",
      "91: accuracy:0.6099290780141844 loss: 0.0006658113010952046 time: 17.352436065673828\n",
      "92: accuracy:0.6099290780141844 loss: 0.0006541049429498561 time: 17.542394876480103\n",
      "93: accuracy:0.6099290780141844 loss: 0.0006750845961442867 time: 17.711962938308716\n",
      "94: accuracy:0.6099290780141844 loss: 0.0006383639619388021 time: 17.913567066192627\n",
      "95: accuracy:0.6099290780141844 loss: 0.0006309395773259904 time: 18.079679012298584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96: accuracy:0.6099290780141844 loss: 0.0006996444944390921 time: 18.249208211898804\n",
      "97: accuracy:0.6099290780141844 loss: 0.0006707171280759309 time: 18.413047075271606\n",
      "98: accuracy:0.6099290780141844 loss: 0.000657162730689593 time: 18.607497930526733\n",
      "99: accuracy:0.6099290780141844 loss: 0.0005525695155582686 time: 18.80419421195984\n",
      "100: accuracy:0.6099290780141844 loss: 0.000656409127055443 time: 18.99507784843445\n",
      "101: accuracy:0.6099290780141844 loss: 0.0006910478282396327 time: 19.18441915512085\n",
      "102: accuracy:0.6099290780141844 loss: 0.0005858998460414964 time: 19.349805116653442\n",
      "103: accuracy:0.6099290780141844 loss: 0.0005914224141634275 time: 19.521262884140015\n",
      "104: accuracy:0.6099290780141844 loss: 0.0005388525933275799 time: 19.688402891159058\n",
      "105: accuracy:0.6099290780141844 loss: 0.0005770309750560936 time: 19.86892294883728\n",
      "106: accuracy:0.6099290780141844 loss: 0.0005366708817185436 time: 20.09344220161438\n",
      "107: accuracy:0.6099290780141844 loss: 0.0005428538133112821 time: 20.301585912704468\n",
      "108: accuracy:0.6099290780141844 loss: 0.0005017845133817137 time: 20.481103897094727\n",
      "109: accuracy:0.6099290780141844 loss: 0.0004599834299997901 time: 20.647402048110962\n",
      "110: accuracy:0.6099290780141844 loss: 0.0005087901371495665 time: 20.822241067886353\n",
      "111: accuracy:0.6099290780141844 loss: 0.0005371308821749743 time: 20.98914098739624\n",
      "112: accuracy:0.6099290780141844 loss: 0.00045159523567916336 time: 21.201469898223877\n",
      "113: accuracy:0.6099290780141844 loss: 0.0004601264254698835 time: 21.459455966949463\n",
      "114: accuracy:0.6099290780141844 loss: 0.0005546473571874624 time: 21.635668992996216\n",
      "115: accuracy:0.6099290780141844 loss: 0.0004085192776933866 time: 21.868315935134888\n",
      "116: accuracy:0.6099290780141844 loss: 0.0005522236580162726 time: 22.084237813949585\n",
      "117: accuracy:0.6099290780141844 loss: 0.00048033982008881536 time: 22.250944137573242\n",
      "118: accuracy:0.6099290780141844 loss: 0.0004959548211610202 time: 22.423645973205566\n",
      "119: accuracy:0.6099290780141844 loss: 0.0004272578216317261 time: 22.60810899734497\n",
      "120: accuracy:0.6099290780141844 loss: 0.00048752789645456165 time: 22.780349016189575\n",
      "121: accuracy:0.6099290780141844 loss: 0.00046461386346427095 time: 22.958688020706177\n",
      "122: accuracy:0.6099290780141844 loss: 0.0004492934919878598 time: 23.12842607498169\n",
      "123: accuracy:0.6099290780141844 loss: 0.00040867379738647816 time: 23.303179025650024\n",
      "124: accuracy:0.6099290780141844 loss: 0.00044011357407888036 time: 23.472285985946655\n",
      "125: accuracy:0.6099290780141844 loss: 0.000456898500584416 time: 23.650595903396606\n",
      "126: accuracy:0.6099290780141844 loss: 0.00038796156568111483 time: 23.82773518562317\n",
      "127: accuracy:0.6099290780141844 loss: 0.00042594885825654975 time: 24.013280153274536\n",
      "128: accuracy:0.6099290780141844 loss: 0.00040954323955610304 time: 24.194967031478882\n",
      "129: accuracy:0.6099290780141844 loss: 0.00042321713372636287 time: 24.37468385696411\n",
      "130: accuracy:0.6099290780141844 loss: 0.0003933159377975163 time: 24.55575203895569\n",
      "131: accuracy:0.6099290780141844 loss: 0.00036883895872693423 time: 24.737142086029053\n",
      "132: accuracy:0.6099290780141844 loss: 0.0003973859870598189 time: 24.914422035217285\n",
      "133: accuracy:0.6099290780141844 loss: 0.00043511258768581687 time: 25.077553033828735\n",
      "134: accuracy:0.6099290780141844 loss: 0.0003602554950305909 time: 25.250741004943848\n",
      "135: accuracy:0.6099290780141844 loss: 0.00043156311759359663 time: 25.41785502433777\n",
      "136: accuracy:0.6099290780141844 loss: 0.00036076981490365615 time: 25.58731698989868\n",
      "137: accuracy:0.6099290780141844 loss: 0.000325634766919133 time: 25.756226062774658\n",
      "138: accuracy:0.6099290780141844 loss: 0.0003596993737789132 time: 25.921101808547974\n",
      "139: accuracy:0.6099290780141844 loss: 0.00035564691173674794 time: 26.17396903038025\n",
      "140: accuracy:0.6099290780141844 loss: 0.0003090613072893156 time: 26.34127902984619\n",
      "141: accuracy:0.6099290780141844 loss: 0.0003471453928159031 time: 26.51224398612976\n",
      "142: accuracy:0.6099290780141844 loss: 0.000339449297248657 time: 26.707087993621826\n",
      "143: accuracy:0.6099290780141844 loss: 0.0003137659474765821 time: 26.88641905784607\n",
      "144: accuracy:0.6099290780141844 loss: 0.00037379667729683214 time: 27.07786989212036\n",
      "145: accuracy:0.6099290780141844 loss: 0.00033310954471992915 time: 27.26025390625\n",
      "146: accuracy:0.6099290780141844 loss: 0.00036102413033224526 time: 27.424280881881714\n",
      "147: accuracy:0.6099290780141844 loss: 0.00032890161567264035 time: 27.62230086326599\n",
      "148: accuracy:0.6099290780141844 loss: 0.0003020683458785684 time: 27.798446893692017\n",
      "149: accuracy:0.6099290780141844 loss: 0.0003214154166051562 time: 28.005470037460327\n",
      "150: accuracy:0.6099290780141844 loss: 0.0002668009071018242 time: 28.191715955734253\n",
      "151: accuracy:0.6099290780141844 loss: 0.00032282241936801374 time: 28.3554630279541\n",
      "152: accuracy:0.6099290780141844 loss: 0.0003052631569273093 time: 28.52223491668701\n",
      "153: accuracy:0.6099290780141844 loss: 0.00028184271075950564 time: 28.693382024765015\n",
      "154: accuracy:0.6099290780141844 loss: 0.0002930018540947924 time: 28.90350103378296\n",
      "155: accuracy:0.6099290780141844 loss: 0.00028705359587371604 time: 29.085901975631714\n",
      "156: accuracy:0.6099290780141844 loss: 0.00031112181903208177 time: 29.256194829940796\n",
      "157: accuracy:0.6099290780141844 loss: 0.00031328659217564334 time: 29.452772855758667\n",
      "158: accuracy:0.6099290780141844 loss: 0.00028782573098574206 time: 29.623493909835815\n",
      "159: accuracy:0.6099290780141844 loss: 0.00027230495892833774 time: 29.811429977416992\n",
      "160: accuracy:0.6099290780141844 loss: 0.00026430077104068673 time: 29.998435974121094\n",
      "161: accuracy:0.6099290780141844 loss: 0.0002619996798630199 time: 30.176525831222534\n",
      "162: accuracy:0.6099290780141844 loss: 0.00028797604332818794 time: 30.36679983139038\n",
      "163: accuracy:0.6099290780141844 loss: 0.00025519064701630916 time: 30.56878113746643\n",
      "164: accuracy:0.6099290780141844 loss: 0.00032220094130842115 time: 30.747880935668945\n",
      "165: accuracy:0.6099290780141844 loss: 0.00026512204782844456 time: 30.91572403907776\n",
      "166: accuracy:0.6099290780141844 loss: 0.00028435398335779585 time: 31.07524299621582\n",
      "167: accuracy:0.6099290780141844 loss: 0.00024727517250583577 time: 31.244960069656372\n",
      "168: accuracy:0.6099290780141844 loss: 0.00024380524391776705 time: 31.459906101226807\n",
      "169: accuracy:0.6099290780141844 loss: 0.0002496673263977099 time: 31.679466009140015\n",
      "170: accuracy:0.6099290780141844 loss: 0.00025242740894345164 time: 31.847055912017822\n",
      "171: accuracy:0.6099290780141844 loss: 0.00026689421146385125 time: 32.012150049209595\n",
      "172: accuracy:0.6099290780141844 loss: 0.0002459407644052598 time: 32.181174993515015\n",
      "173: accuracy:0.6099290780141844 loss: 0.00023094229300327942 time: 32.38607692718506\n",
      "174: accuracy:0.6099290780141844 loss: 0.00023345111748375962 time: 32.596564054489136\n",
      "175: accuracy:0.6099290780141844 loss: 0.00022726932384173893 time: 32.777154207229614\n",
      "176: accuracy:0.6099290780141844 loss: 0.0002512059467328623 time: 32.94482421875\n",
      "177: accuracy:0.6099290780141844 loss: 0.0002468007794138519 time: 33.10337686538696\n",
      "178: accuracy:0.6099290780141844 loss: 0.00022892645415047193 time: 33.27983117103577\n",
      "179: accuracy:0.6099290780141844 loss: 0.00018238141240307015 time: 33.486101150512695\n",
      "180: accuracy:0.6099290780141844 loss: 0.00022406704285710282 time: 33.70065999031067\n",
      "181: accuracy:0.6099290780141844 loss: 0.00022596896263308455 time: 33.88311004638672\n",
      "182: accuracy:0.6099290780141844 loss: 0.00021216760186091628 time: 34.072937965393066\n",
      "183: accuracy:0.6099290780141844 loss: 0.00021257614007824189 time: 34.25465512275696\n",
      "184: accuracy:0.6099290780141844 loss: 0.0002578408046641937 time: 34.429837226867676\n",
      "185: accuracy:0.6099290780141844 loss: 0.00023636933309717023 time: 34.61678910255432\n",
      "186: accuracy:0.6099290780141844 loss: 0.00023978690997536388 time: 34.800617933273315\n",
      "187: accuracy:0.6099290780141844 loss: 0.0002087295735930742 time: 34.98484516143799\n",
      "188: accuracy:0.6099290780141844 loss: 0.0002182806950280661 time: 35.16629886627197\n",
      "189: accuracy:0.6099290780141844 loss: 0.00021532687311810302 time: 35.37020707130432\n",
      "190: accuracy:0.6099290780141844 loss: 0.00026105028206967315 time: 35.56700086593628\n",
      "191: accuracy:0.6028368794326241 loss: 0.00019926392063083855 time: 35.75096821784973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192: accuracy:0.6028368794326241 loss: 0.00020562667626083147 time: 35.931596994400024\n",
      "193: accuracy:0.6028368794326241 loss: 0.00019052557570703295 time: 36.13655209541321\n",
      "194: accuracy:0.6028368794326241 loss: 0.0002107609963320378 time: 36.33964800834656\n",
      "195: accuracy:0.6028368794326241 loss: 0.00019450586827836705 time: 36.545604944229126\n",
      "196: accuracy:0.6028368794326241 loss: 0.0001975190969800446 time: 36.75263500213623\n",
      "197: accuracy:0.6028368794326241 loss: 0.0001988417631102151 time: 36.96147584915161\n",
      "198: accuracy:0.6028368794326241 loss: 0.00018871846322655118 time: 37.17354083061218\n",
      "199: accuracy:0.6028368794326241 loss: 0.00020135617760203166 time: 37.37429690361023\n",
      "200: accuracy:0.6099290780141844 loss: 0.00021362233706746027 time: 37.57643699645996\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = CNN()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "start = time.time()\n",
    "for epoch in range(1,201): \n",
    "    for step, (batch_x, sen, batch_y) in enumerate(loader):\n",
    "        pred = net(batch_x)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_e)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss} time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
