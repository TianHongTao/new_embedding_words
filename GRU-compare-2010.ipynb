{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function set_backend in module tensorly:\n",
      "\n",
      "set_backend(backend_name)\n",
      "    Sets the backend for TensorLy\n",
      "    \n",
      "        The backend will be set as specified and operations will used that backend\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    backend_name : {'mxnet', 'numpy', 'pytorch', 'tensorflow', 'cupy'}, default is 'numpy'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 128\n",
    "tl.set_backend('pytorch')\n",
    "help(tl.set_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 85, 200), (8000,), (8000,), (8000,), (8000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.fromfile('tensors_2010.dat',dtype=np.float64).reshape((8000,-1,200))\n",
    "Y = np.fromfile('tensors_2010_labels.dat',dtype=np.int)\n",
    "position_tag_1 = np.fromfile('tensors_2010_entity1.dat',dtype=np.int)\n",
    "position_tag_2 = np.fromfile('tensors_2010_entity2.dat',dtype=np.int)\n",
    "position_tag = np.concatenate((position_tag_1,position_tag_2)).reshape((8000,-1))\n",
    "b.shape,Y.shape,position_tag_1.shape,position_tag_2.shape,position_tag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(8000):\n",
    "    inputs.append((torch.from_numpy(b[i]),Y[i]))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2400, 85, 200]), torch.Size([2400]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_e = []\n",
    "t_y = []\n",
    "for E,Y in test:\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "t_e = torch.stack(t_e)\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_e.shape, t_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_rnn_max: 0.6158333333333333 4轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN_max(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = 200,       # rnn input\n",
    "            hidden_size = 64,     # rnn hidden unit\n",
    "            num_layers = 1,       # 有几层 RNN layers\n",
    "            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out=torch.nn.Linear(in_features=64,out_features=10)\n",
    "        self.maxpool = torch.nn.MaxPool2d((85,1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        output,h_n=self.rnn(x.float())\n",
    "        output_in_last_timestep = self.maxpool(output)\n",
    "        output_in_last_timestep = output_in_last_timestep.reshape((output_in_last_timestep.shape[0],-1))\n",
    "        x=self.out(output_in_last_timestep)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_max(\n",
      "  (rnn): GRU(200, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=(85, 1), stride=(85, 1), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "1: accuracy:0.17375 loss: 2.3217885494232178\n",
      "2: accuracy:0.5570833333333334 loss: 1.1998502016067505\n",
      "3: accuracy:0.58 loss: 0.9416068196296692\n",
      "4: accuracy:0.6158333333333333 loss: 0.7349043488502502\n",
      "5: accuracy:0.6058333333333333 loss: 0.5695826411247253\n",
      "6: accuracy:0.6054166666666667 loss: 0.38526633381843567\n",
      "7: accuracy:0.5920833333333333 loss: 0.24833987653255463\n",
      "8: accuracy:0.6029166666666667 loss: 0.2028799206018448\n",
      "9: accuracy:0.5916666666666667 loss: 0.11811262369155884\n",
      "10: accuracy:0.6 loss: 0.06206924840807915\n",
      "11: accuracy:0.6033333333333334 loss: 0.043837450444698334\n",
      "12: accuracy:0.5833333333333334 loss: 0.027932940050959587\n",
      "13: accuracy:0.5983333333333334 loss: 0.015282370150089264\n",
      "14: accuracy:0.59875 loss: 0.009410955011844635\n",
      "15: accuracy:0.5991666666666666 loss: 0.008061084896326065\n",
      "16: accuracy:0.5933333333333334 loss: 0.005909301340579987\n",
      "17: accuracy:0.6020833333333333 loss: 0.005187541246414185\n",
      "18: accuracy:0.5979166666666667 loss: 0.004002649337053299\n",
      "19: accuracy:0.60125 loss: 0.004333987832069397\n",
      "20: accuracy:0.59875 loss: 0.0042925067245960236\n",
      "21: accuracy:0.5933333333333334 loss: 0.002993989735841751\n",
      "22: accuracy:0.5983333333333334 loss: 0.003424026072025299\n",
      "23: accuracy:0.6016666666666667 loss: 0.008983124047517776\n",
      "24: accuracy:0.5983333333333334 loss: 0.0021653249859809875\n",
      "25: accuracy:0.5995833333333334 loss: 0.0019227229058742523\n",
      "26: accuracy:0.5995833333333334 loss: 0.002002410590648651\n",
      "27: accuracy:0.5716666666666667 loss: 0.4423924684524536\n",
      "28: accuracy:0.5533333333333333 loss: 0.4306037127971649\n",
      "29: accuracy:0.56625 loss: 0.28682610392570496\n",
      "30: accuracy:0.59375 loss: 0.12224413454532623\n",
      "31: accuracy:0.58625 loss: 0.08752907067537308\n",
      "32: accuracy:0.5920833333333333 loss: 0.02944057062268257\n",
      "33: accuracy:0.595 loss: 0.019055742770433426\n",
      "34: accuracy:0.5975 loss: 0.008365791290998459\n",
      "35: accuracy:0.5983333333333334 loss: 0.013472076505422592\n",
      "36: accuracy:0.59875 loss: 0.005465738475322723\n",
      "37: accuracy:0.5941666666666666 loss: 0.00457405298948288\n",
      "38: accuracy:0.59875 loss: 0.004539173096418381\n",
      "39: accuracy:0.5979166666666667 loss: 0.0033548101782798767\n",
      "40: accuracy:0.5970833333333333 loss: 0.0027263276278972626\n",
      "41: accuracy:0.5975 loss: 0.003095202147960663\n",
      "42: accuracy:0.5966666666666667 loss: 0.002354096621274948\n",
      "43: accuracy:0.5979166666666667 loss: 0.0022718682885169983\n",
      "44: accuracy:0.5954166666666667 loss: 0.0018437132239341736\n",
      "45: accuracy:0.5966666666666667 loss: 0.001779649406671524\n",
      "46: accuracy:0.59375 loss: 0.0017873309552669525\n",
      "47: accuracy:0.5929166666666666 loss: 0.001971125602722168\n",
      "48: accuracy:0.5941666666666666 loss: 0.006850402802228928\n",
      "49: accuracy:0.5979166666666667 loss: 0.0016516782343387604\n",
      "50: accuracy:0.5925 loss: 0.001375880092382431\n",
      "51: accuracy:0.59375 loss: 0.0014592818915843964\n",
      "52: accuracy:0.5983333333333334 loss: 0.00506095215678215\n",
      "53: accuracy:0.5916666666666667 loss: 0.0011196136474609375\n",
      "54: accuracy:0.5920833333333333 loss: 0.001227591186761856\n",
      "55: accuracy:0.59375 loss: 0.001313570886850357\n",
      "56: accuracy:0.59875 loss: 0.005007866770029068\n",
      "57: accuracy:0.5916666666666667 loss: 0.0009868443012237549\n",
      "58: accuracy:0.59375 loss: 0.002390451729297638\n",
      "59: accuracy:0.5958333333333333 loss: 0.0007231160998344421\n",
      "60: accuracy:0.5954166666666667 loss: 0.0011711381375789642\n",
      "61: accuracy:0.5916666666666667 loss: 0.0007895082235336304\n",
      "62: accuracy:0.59625 loss: 0.0006927885115146637\n",
      "63: accuracy:0.5954166666666667 loss: 0.0008985884487628937\n",
      "64: accuracy:0.5979166666666667 loss: 0.0006891041994094849\n",
      "65: accuracy:0.5975 loss: 0.0008146241307258606\n",
      "66: accuracy:0.5941666666666666 loss: 0.0006436780095100403\n",
      "67: accuracy:0.5979166666666667 loss: 0.0006825439631938934\n",
      "68: accuracy:0.5966666666666667 loss: 0.0007196813821792603\n",
      "69: accuracy:0.5995833333333334 loss: 0.005763929337263107\n",
      "70: accuracy:0.5979166666666667 loss: 0.000699169933795929\n",
      "71: accuracy:0.5983333333333334 loss: 0.0005363263189792633\n",
      "72: accuracy:0.5983333333333334 loss: 0.000547364354133606\n",
      "73: accuracy:0.6 loss: 0.009188201278448105\n",
      "74: accuracy:0.60125 loss: 0.0004776902496814728\n",
      "75: accuracy:0.5983333333333334 loss: 0.0005301609635353088\n",
      "76: accuracy:0.6004166666666667 loss: 0.00038268789649009705\n",
      "77: accuracy:0.5954166666666667 loss: 0.0005324035882949829\n",
      "78: accuracy:0.5995833333333334 loss: 0.0004323311150074005\n",
      "79: accuracy:0.6008333333333333 loss: 0.00031405314803123474\n",
      "80: accuracy:0.5995833333333334 loss: 0.00033422932028770447\n",
      "81: accuracy:0.6004166666666667 loss: 0.0003726854920387268\n",
      "82: accuracy:0.605 loss: 0.0004305616021156311\n",
      "83: accuracy:0.6008333333333333 loss: 0.00039440765976905823\n",
      "84: accuracy:0.5958333333333333 loss: 0.0003490522503852844\n",
      "85: accuracy:0.60125 loss: 0.0004045143723487854\n",
      "86: accuracy:0.5991666666666666 loss: 0.0003681853413581848\n",
      "87: accuracy:0.6 loss: 0.0003017596900463104\n",
      "88: accuracy:0.6029166666666667 loss: 0.00028957054018974304\n",
      "89: accuracy:0.5970833333333333 loss: 0.00032624974846839905\n",
      "90: accuracy:0.6020833333333333 loss: 0.016138363629579544\n",
      "91: accuracy:0.60125 loss: 0.0002796873450279236\n",
      "92: accuracy:0.6004166666666667 loss: 0.00026448071002960205\n",
      "93: accuracy:0.5995833333333334 loss: 0.00028086453676223755\n",
      "94: accuracy:0.5983333333333334 loss: 0.00023952871561050415\n",
      "95: accuracy:0.5995833333333334 loss: 0.0002810470759868622\n",
      "96: accuracy:0.6008333333333333 loss: 0.0002355128526687622\n",
      "97: accuracy:0.6041666666666666 loss: 0.0002469457685947418\n",
      "98: accuracy:0.5945833333333334 loss: 0.00025099143385887146\n",
      "99: accuracy:0.6004166666666667 loss: 0.00026679039001464844\n",
      "100: accuracy:0.6016666666666667 loss: 0.0001902468502521515\n",
      "101: accuracy:0.6033333333333334 loss: 0.0027976855635643005\n",
      "102: accuracy:0.5958333333333333 loss: 0.0002464316785335541\n",
      "103: accuracy:0.6041666666666666 loss: 0.00016397982835769653\n",
      "104: accuracy:0.6020833333333333 loss: 0.00018035992980003357\n",
      "105: accuracy:0.59875 loss: 0.00019485130906105042\n",
      "106: accuracy:0.6066666666666667 loss: 0.00017624348402023315\n",
      "107: accuracy:0.6020833333333333 loss: 0.00014452636241912842\n",
      "108: accuracy:0.6058333333333333 loss: 0.00041851773858070374\n",
      "109: accuracy:0.5991666666666666 loss: 0.000371783971786499\n",
      "110: accuracy:0.60875 loss: 0.00022792816162109375\n",
      "111: accuracy:0.5991666666666666 loss: 0.0005959607660770416\n",
      "112: accuracy:0.4970833333333333 loss: 1.0660614967346191\n",
      "113: accuracy:0.52375 loss: 0.7681602239608765\n",
      "114: accuracy:0.5333333333333333 loss: 0.5349382162094116\n",
      "115: accuracy:0.5520833333333334 loss: 0.3546372354030609\n",
      "116: accuracy:0.5620833333333334 loss: 0.20956020057201385\n",
      "117: accuracy:0.5541666666666667 loss: 0.10761241614818573\n",
      "118: accuracy:0.56 loss: 0.07010453939437866\n",
      "119: accuracy:0.5533333333333333 loss: 0.03157193958759308\n",
      "120: accuracy:0.5608333333333333 loss: 0.03155528008937836\n",
      "121: accuracy:0.5591666666666667 loss: 0.020108662545681\n",
      "122: accuracy:0.55375 loss: 0.024190109223127365\n",
      "123: accuracy:0.5616666666666666 loss: 0.014040060341358185\n",
      "124: accuracy:0.5608333333333333 loss: 0.011315900832414627\n",
      "125: accuracy:0.5625 loss: 0.009670713916420937\n",
      "126: accuracy:0.5641666666666667 loss: 0.007642451673746109\n",
      "127: accuracy:0.5616666666666666 loss: 0.013576112687587738\n",
      "128: accuracy:0.5625 loss: 0.006393585354089737\n",
      "129: accuracy:0.56375 loss: 0.005752433091402054\n",
      "130: accuracy:0.5629166666666666 loss: 0.005839783698320389\n",
      "131: accuracy:0.5625 loss: 0.005979975685477257\n",
      "132: accuracy:0.5629166666666666 loss: 0.009366687387228012\n",
      "133: accuracy:0.5641666666666667 loss: 0.005541764199733734\n",
      "134: accuracy:0.56375 loss: 0.0052337683737277985\n",
      "135: accuracy:0.5641666666666667 loss: 0.004703778773546219\n",
      "136: accuracy:0.5641666666666667 loss: 0.003365129232406616\n",
      "137: accuracy:0.5658333333333333 loss: 0.00717756524682045\n",
      "138: accuracy:0.56375 loss: 0.003745630383491516\n",
      "139: accuracy:0.5645833333333333 loss: 0.002887450158596039\n",
      "140: accuracy:0.5633333333333334 loss: 0.0037491805851459503\n",
      "141: accuracy:0.565 loss: 0.00315919890999794\n",
      "142: accuracy:0.5658333333333333 loss: 0.0035361386835575104\n",
      "143: accuracy:0.5675 loss: 0.0024967826902866364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144: accuracy:0.5641666666666667 loss: 0.002643834799528122\n",
      "145: accuracy:0.5654166666666667 loss: 0.0026444606482982635\n",
      "146: accuracy:0.5633333333333334 loss: 0.0025319792330265045\n",
      "147: accuracy:0.5641666666666667 loss: 0.002333667129278183\n",
      "148: accuracy:0.5641666666666667 loss: 0.0017496980726718903\n",
      "149: accuracy:0.56375 loss: 0.0022230856120586395\n",
      "150: accuracy:0.5654166666666667 loss: 0.001850184053182602\n",
      "151: accuracy:0.5645833333333333 loss: 0.0017025582492351532\n",
      "152: accuracy:0.5666666666666667 loss: 0.0016517601907253265\n",
      "153: accuracy:0.5608333333333333 loss: 0.0017395354807376862\n",
      "154: accuracy:0.5633333333333334 loss: 0.0013730302453041077\n",
      "155: accuracy:0.5658333333333333 loss: 0.0019898563623428345\n",
      "156: accuracy:0.5616666666666666 loss: 0.0015384480357170105\n",
      "157: accuracy:0.5591666666666667 loss: 0.0013953819870948792\n",
      "158: accuracy:0.56625 loss: 0.0016397014260292053\n",
      "159: accuracy:0.5675 loss: 0.0011992249637842178\n",
      "160: accuracy:0.5616666666666666 loss: 0.0015268884599208832\n",
      "161: accuracy:0.5658333333333333 loss: 0.0014191195368766785\n",
      "162: accuracy:0.56375 loss: 0.0013030655682086945\n",
      "163: accuracy:0.5645833333333333 loss: 0.000958811491727829\n",
      "164: accuracy:0.5629166666666666 loss: 0.0012094266712665558\n",
      "165: accuracy:0.565 loss: 0.0009591355919837952\n",
      "166: accuracy:0.565 loss: 0.0008813254535198212\n",
      "167: accuracy:0.5691666666666667 loss: 0.0011865906417369843\n",
      "168: accuracy:0.5633333333333334 loss: 0.000938858836889267\n",
      "169: accuracy:0.5625 loss: 0.0006868168711662292\n",
      "170: accuracy:0.5633333333333334 loss: 0.0010395348072052002\n",
      "171: accuracy:0.5625 loss: 0.0008831359446048737\n",
      "172: accuracy:0.5675 loss: 0.0006784200668334961\n",
      "173: accuracy:0.56125 loss: 0.0009235553443431854\n",
      "174: accuracy:0.56375 loss: 0.0007178224623203278\n",
      "175: accuracy:0.56375 loss: 0.000884179025888443\n",
      "176: accuracy:0.5645833333333333 loss: 0.000535823404788971\n",
      "177: accuracy:0.5629166666666666 loss: 0.0007540471851825714\n",
      "178: accuracy:0.5625 loss: 0.0006244629621505737\n",
      "179: accuracy:0.56375 loss: 0.0007923729717731476\n",
      "180: accuracy:0.5620833333333334 loss: 0.0006531700491905212\n",
      "181: accuracy:0.56 loss: 0.007114917039871216\n",
      "182: accuracy:0.56 loss: 0.00995638594031334\n",
      "183: accuracy:0.5604166666666667 loss: 0.0005607642233371735\n",
      "184: accuracy:0.5604166666666667 loss: 0.0005269944667816162\n",
      "185: accuracy:0.5625 loss: 0.0006179101765155792\n",
      "186: accuracy:0.56 loss: 0.000596165657043457\n",
      "187: accuracy:0.5629166666666666 loss: 0.0005595460534095764\n",
      "188: accuracy:0.5675 loss: 0.0004835464060306549\n",
      "189: accuracy:0.56125 loss: 0.0004128068685531616\n",
      "190: accuracy:0.56125 loss: 0.000582769513130188\n",
      "191: accuracy:0.56625 loss: 0.0007368624210357666\n",
      "192: accuracy:0.56 loss: 0.0005167163908481598\n",
      "193: accuracy:0.56625 loss: 0.00040735676884651184\n",
      "194: accuracy:0.5604166666666667 loss: 0.0004167817533016205\n",
      "195: accuracy:0.55875 loss: 0.0003504529595375061\n",
      "196: accuracy:0.5620833333333334 loss: 0.00041390955448150635\n",
      "197: accuracy:0.5595833333333333 loss: 0.0003855787217617035\n",
      "198: accuracy:0.5583333333333333 loss: 0.00040108710527420044\n",
      "199: accuracy:0.55875 loss: 0.00031102821230888367\n",
      "200: accuracy:0.5595833333333333 loss: 0.0004350505769252777\n",
      "201: accuracy:0.5629166666666666 loss: 0.00036640092730522156\n",
      "202: accuracy:0.5575 loss: 0.00026907026767730713\n",
      "203: accuracy:0.5583333333333333 loss: 0.0003243647515773773\n",
      "204: accuracy:0.5625 loss: 0.0003411732614040375\n",
      "205: accuracy:0.5583333333333333 loss: 0.00027723610401153564\n",
      "206: accuracy:0.5625 loss: 0.0002677999436855316\n",
      "207: accuracy:0.5608333333333333 loss: 0.00023993104696273804\n",
      "208: accuracy:0.5608333333333333 loss: 0.00027607008814811707\n",
      "209: accuracy:0.5595833333333333 loss: 0.002306383103132248\n",
      "210: accuracy:0.5608333333333333 loss: 0.00026192888617515564\n",
      "211: accuracy:0.56125 loss: 0.0002635270357131958\n",
      "212: accuracy:0.5591666666666667 loss: 0.0002648495137691498\n",
      "213: accuracy:0.5604166666666667 loss: 0.0069167837500572205\n",
      "214: accuracy:0.55875 loss: 0.0002583898603916168\n",
      "215: accuracy:0.5595833333333333 loss: 0.00591682642698288\n",
      "216: accuracy:0.5595833333333333 loss: 0.00026877596974372864\n",
      "217: accuracy:0.5641666666666667 loss: 0.004378624260425568\n",
      "218: accuracy:0.5583333333333333 loss: 0.0002090558409690857\n",
      "219: accuracy:0.5566666666666666 loss: 0.00017675384879112244\n",
      "220: accuracy:0.5570833333333334 loss: 0.00018728524446487427\n",
      "221: accuracy:0.5620833333333334 loss: 0.0002365894615650177\n",
      "222: accuracy:0.5579166666666666 loss: 0.00019270926713943481\n",
      "223: accuracy:0.55875 loss: 0.017639368772506714\n",
      "224: accuracy:0.5579166666666666 loss: 0.00015885010361671448\n",
      "225: accuracy:0.5629166666666666 loss: 0.00021221861243247986\n",
      "226: accuracy:0.55625 loss: 0.00019488483667373657\n",
      "227: accuracy:0.5570833333333334 loss: 0.00013328343629837036\n",
      "228: accuracy:0.5604166666666667 loss: 0.00015407800674438477\n",
      "229: accuracy:0.5579166666666666 loss: 0.00016254186630249023\n",
      "230: accuracy:0.55875 loss: 0.00018499046564102173\n",
      "231: accuracy:0.5579166666666666 loss: 0.00016774609684944153\n",
      "232: accuracy:0.5570833333333334 loss: 0.000136692076921463\n",
      "233: accuracy:0.5591666666666667 loss: 0.00014741718769073486\n",
      "234: accuracy:0.56125 loss: 0.0001345425844192505\n",
      "235: accuracy:0.5575 loss: 0.00955108180642128\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = RNN_max()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "for epoch in range(1,301): \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        pred = net(batch_x)\n",
    "        loss = loss_F(pred,batch_y) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_e)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove_bi-rnn_max: 0.6158333333333333 4轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class bi_RNN_max(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = 200,       # rnn input\n",
    "            hidden_size = 64,     # rnn hidden unit\n",
    "            num_layers = 1,       # 有几层 RNN layers\n",
    "            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.out=torch.nn.Linear(in_features=128,out_features=10)\n",
    "        self.maxpool = torch.nn.MaxPool2d((85,1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        output,h_n=self.rnn(x.float())\n",
    "        output_in_last_timestep = self.maxpool(output)\n",
    "        output_in_last_timestep = output_in_last_timestep.reshape((output_in_last_timestep.shape[0],-1))\n",
    "        x=self.out(output_in_last_timestep)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bi_RNN_max(\n",
      "  (rnn): GRU(200, 64, batch_first=True, bidirectional=True)\n",
      "  (out): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=(85, 1), stride=(85, 1), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "1: accuracy:0.18333333333333332 loss: 2.219050407409668\n",
      "2: accuracy:0.5733333333333334 loss: 0.9770408272743225\n",
      "3: accuracy:0.6091666666666666 loss: 0.8143296837806702\n",
      "4: accuracy:0.6216666666666667 loss: 0.5164687633514404\n",
      "5: accuracy:0.6066666666666667 loss: 0.3578956723213196\n",
      "6: accuracy:0.6266666666666667 loss: 0.164963036775589\n",
      "7: accuracy:0.6045833333333334 loss: 0.09574701637029648\n",
      "8: accuracy:0.61875 loss: 0.03480490669608116\n",
      "9: accuracy:0.6195833333333334 loss: 0.02018904685974121\n",
      "10: accuracy:0.61625 loss: 0.009954210370779037\n",
      "11: accuracy:0.6216666666666667 loss: 0.007833383977413177\n",
      "12: accuracy:0.6183333333333333 loss: 0.006788436323404312\n",
      "13: accuracy:0.6183333333333333 loss: 0.005218572914600372\n",
      "14: accuracy:0.6191666666666666 loss: 0.01804867945611477\n",
      "15: accuracy:0.6179166666666667 loss: 0.0036908015608787537\n",
      "16: accuracy:0.6175 loss: 0.002224314957857132\n",
      "17: accuracy:0.6179166666666667 loss: 0.002483867108821869\n",
      "18: accuracy:0.6175 loss: 0.0020548775792121887\n",
      "19: accuracy:0.61875 loss: 0.0019139312207698822\n",
      "20: accuracy:0.6158333333333333 loss: 0.0015239007771015167\n",
      "21: accuracy:0.6183333333333333 loss: 0.0014133453369140625\n",
      "22: accuracy:0.6175 loss: 0.001712266355752945\n",
      "23: accuracy:0.6179166666666667 loss: 0.0015050098299980164\n",
      "24: accuracy:0.6191666666666666 loss: 0.0011046156287193298\n",
      "25: accuracy:0.6158333333333333 loss: 0.0010611414909362793\n",
      "26: accuracy:0.61625 loss: 0.0009764544665813446\n",
      "27: accuracy:0.6175 loss: 0.0008522756397724152\n",
      "28: accuracy:0.6179166666666667 loss: 0.0008328035473823547\n",
      "29: accuracy:0.61875 loss: 0.0007715784013271332\n",
      "30: accuracy:0.6158333333333333 loss: 0.0007990896701812744\n",
      "31: accuracy:0.61875 loss: 0.0006091296672821045\n",
      "32: accuracy:0.6183333333333333 loss: 0.0005466006696224213\n",
      "33: accuracy:0.615 loss: 0.0006074532866477966\n",
      "34: accuracy:0.6183333333333333 loss: 0.000606633722782135\n",
      "35: accuracy:0.62 loss: 0.0005707331001758575\n",
      "36: accuracy:0.6191666666666666 loss: 0.0005221813917160034\n",
      "37: accuracy:0.6191666666666666 loss: 0.00047650188207626343\n",
      "38: accuracy:0.6170833333333333 loss: 0.00045120343565940857\n",
      "39: accuracy:0.615 loss: 0.0005175434052944183\n",
      "40: accuracy:0.6179166666666667 loss: 0.00033689290285110474\n",
      "41: accuracy:0.615 loss: 0.0003311857581138611\n",
      "42: accuracy:0.61875 loss: 0.0003120303153991699\n",
      "43: accuracy:0.61875 loss: 0.00034954026341438293\n",
      "44: accuracy:0.6166666666666667 loss: 0.00031385570764541626\n",
      "45: accuracy:0.6195833333333334 loss: 0.0002803690731525421\n",
      "46: accuracy:0.61375 loss: 0.0003211572766304016\n",
      "47: accuracy:0.61875 loss: 0.0003086104989051819\n",
      "48: accuracy:0.6179166666666667 loss: 0.00022739171981811523\n",
      "49: accuracy:0.62125 loss: 0.0002462714910507202\n",
      "50: accuracy:0.6195833333333334 loss: 0.0002318844199180603\n",
      "51: accuracy:0.6175 loss: 0.0002347305417060852\n",
      "52: accuracy:0.6104166666666667 loss: 0.0002505593001842499\n",
      "53: accuracy:0.6125 loss: 0.0002186596393585205\n",
      "54: accuracy:0.6204166666666666 loss: 0.00020746514201164246\n",
      "55: accuracy:0.6179166666666667 loss: 0.00019697099924087524\n",
      "56: accuracy:0.6220833333333333 loss: 0.0001548267900943756\n",
      "57: accuracy:0.6125 loss: 0.00019327551126480103\n",
      "58: accuracy:0.61875 loss: 0.00017342716455459595\n",
      "59: accuracy:0.6208333333333333 loss: 0.00015492737293243408\n",
      "60: accuracy:0.6183333333333333 loss: 0.0001278221607208252\n",
      "61: accuracy:0.6216666666666667 loss: 0.00016427412629127502\n",
      "62: accuracy:0.6208333333333333 loss: 0.00013720989227294922\n",
      "63: accuracy:0.6145833333333334 loss: 0.00013734027743339539\n",
      "64: accuracy:0.6154166666666666 loss: 0.00013531744480133057\n",
      "65: accuracy:0.6170833333333333 loss: 0.00013201311230659485\n",
      "66: accuracy:0.6154166666666666 loss: 0.00012297183275222778\n",
      "67: accuracy:0.62125 loss: 0.0001457110047340393\n",
      "68: accuracy:0.61875 loss: 0.00012325122952461243\n",
      "69: accuracy:0.6191666666666666 loss: 0.008677206933498383\n",
      "70: accuracy:0.45875 loss: 0.9603884220123291\n",
      "71: accuracy:0.5370833333333334 loss: 0.5908561944961548\n",
      "72: accuracy:0.5279166666666667 loss: 0.4163690507411957\n",
      "73: accuracy:0.56625 loss: 0.13497760891914368\n",
      "74: accuracy:0.5683333333333334 loss: 0.05608910322189331\n",
      "75: accuracy:0.5608333333333333 loss: 0.02654319815337658\n",
      "76: accuracy:0.56875 loss: 0.011637361720204353\n",
      "77: accuracy:0.5708333333333333 loss: 0.011095169931650162\n",
      "78: accuracy:0.5704166666666667 loss: 0.008571391925215721\n",
      "79: accuracy:0.5704166666666667 loss: 0.006551144644618034\n",
      "80: accuracy:0.5720833333333334 loss: 0.006397990509867668\n",
      "81: accuracy:0.5683333333333334 loss: 0.005142778158187866\n",
      "82: accuracy:0.5725 loss: 0.013277707621455193\n",
      "83: accuracy:0.57125 loss: 0.003402967005968094\n",
      "84: accuracy:0.5704166666666667 loss: 0.003665611147880554\n",
      "85: accuracy:0.57 loss: 0.00285957008600235\n",
      "86: accuracy:0.5720833333333334 loss: 0.0025274381041526794\n",
      "87: accuracy:0.5716666666666667 loss: 0.0029826872050762177\n",
      "88: accuracy:0.5720833333333334 loss: 0.002473175525665283\n",
      "89: accuracy:0.5704166666666667 loss: 0.003287211060523987\n",
      "90: accuracy:0.5708333333333333 loss: 0.0019257329404354095\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = bi_RNN_max()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "for epoch in range(1,301): \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        pred = net(batch_x)\n",
    "        loss = loss_F(pred,batch_y) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_e)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glove:0.44680851063829785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN_old(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = 200,       # rnn input\n",
    "            hidden_size = 64,     # rnn hidden unit\n",
    "            num_layers = 1,       # 有几层 RNN layers\n",
    "            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)\n",
    "        )        \n",
    "        self.out=torch.nn.Linear(in_features=64,out_features=10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output,h_n=self.rnn(x.float())\n",
    "        output_in_last_timestep=h_n[-1,:,:]\n",
    "        x=self.out(output_in_last_timestep)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_old(\n",
      "  (rnn): GRU(200, 64, batch_first=True)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "1: accuracy:0.12056737588652482 loss: 2.2877795696258545\n",
      "2: accuracy:0.12056737588652482 loss: 2.292205333709717\n",
      "3: accuracy:0.12056737588652482 loss: 2.203953742980957\n",
      "4: accuracy:0.12056737588652482 loss: 2.2441458702087402\n",
      "5: accuracy:0.12056737588652482 loss: 2.2280540466308594\n",
      "6: accuracy:0.12056737588652482 loss: 2.223677396774292\n",
      "7: accuracy:0.12056737588652482 loss: 2.2504940032958984\n",
      "8: accuracy:0.12056737588652482 loss: 2.2234230041503906\n",
      "9: accuracy:0.12056737588652482 loss: 2.2240872383117676\n",
      "10: accuracy:0.12056737588652482 loss: 2.212447166442871\n",
      "11: accuracy:0.12056737588652482 loss: 2.248894691467285\n",
      "12: accuracy:0.12056737588652482 loss: 2.1920266151428223\n",
      "13: accuracy:0.12056737588652482 loss: 2.232753038406372\n",
      "14: accuracy:0.12056737588652482 loss: 2.218202590942383\n",
      "15: accuracy:0.12056737588652482 loss: 2.3168013095855713\n",
      "16: accuracy:0.12056737588652482 loss: 2.3227713108062744\n",
      "17: accuracy:0.12056737588652482 loss: 2.193859338760376\n",
      "18: accuracy:0.12056737588652482 loss: 2.2598063945770264\n",
      "19: accuracy:0.12056737588652482 loss: 2.235846519470215\n",
      "20: accuracy:0.12056737588652482 loss: 2.222870349884033\n",
      "21: accuracy:0.16312056737588654 loss: 2.1808247566223145\n",
      "22: accuracy:0.16312056737588654 loss: 2.1261844635009766\n",
      "23: accuracy:0.2127659574468085 loss: 2.050637722015381\n",
      "24: accuracy:0.20567375886524822 loss: 1.9393036365509033\n",
      "25: accuracy:0.2198581560283688 loss: 1.9542522430419922\n",
      "26: accuracy:0.19148936170212766 loss: 1.558090090751648\n",
      "27: accuracy:0.22695035460992907 loss: 1.9149274826049805\n",
      "28: accuracy:0.22695035460992907 loss: 1.7288836240768433\n",
      "29: accuracy:0.19858156028368795 loss: 1.5888748168945312\n",
      "30: accuracy:0.22695035460992907 loss: 1.6650222539901733\n",
      "31: accuracy:0.22695035460992907 loss: 1.5115230083465576\n",
      "32: accuracy:0.2127659574468085 loss: 1.5106152296066284\n",
      "33: accuracy:0.23404255319148937 loss: 1.5417627096176147\n",
      "34: accuracy:0.18439716312056736 loss: 1.1971009969711304\n",
      "35: accuracy:0.22695035460992907 loss: 1.4701858758926392\n",
      "36: accuracy:0.2127659574468085 loss: 1.5057837963104248\n",
      "37: accuracy:0.28368794326241137 loss: 1.3818011283874512\n",
      "38: accuracy:0.19148936170212766 loss: 1.5220564603805542\n",
      "39: accuracy:0.2624113475177305 loss: 1.49313485622406\n",
      "40: accuracy:0.24822695035460993 loss: 1.314907431602478\n",
      "41: accuracy:0.23404255319148937 loss: 1.2151457071304321\n",
      "42: accuracy:0.2198581560283688 loss: 1.2390145063400269\n",
      "43: accuracy:0.24113475177304963 loss: 1.3552436828613281\n",
      "44: accuracy:0.24822695035460993 loss: 1.6146031618118286\n",
      "45: accuracy:0.22695035460992907 loss: 1.430855393409729\n",
      "46: accuracy:0.19148936170212766 loss: 1.299423336982727\n",
      "47: accuracy:0.19858156028368795 loss: 1.4836971759796143\n",
      "48: accuracy:0.2695035460992908 loss: 1.1404463052749634\n",
      "49: accuracy:0.2907801418439716 loss: 1.3335351943969727\n",
      "50: accuracy:0.2907801418439716 loss: 1.1560652256011963\n",
      "51: accuracy:0.2765957446808511 loss: 0.9254339933395386\n",
      "52: accuracy:0.2978723404255319 loss: 1.2998263835906982\n",
      "53: accuracy:0.2978723404255319 loss: 1.2584171295166016\n",
      "54: accuracy:0.24822695035460993 loss: 1.0804461240768433\n",
      "55: accuracy:0.22695035460992907 loss: 0.973858654499054\n",
      "56: accuracy:0.2978723404255319 loss: 0.6843604445457458\n",
      "57: accuracy:0.2553191489361702 loss: 0.8994130492210388\n",
      "58: accuracy:0.2553191489361702 loss: 0.967761218547821\n",
      "59: accuracy:0.2765957446808511 loss: 1.0374419689178467\n",
      "60: accuracy:0.24822695035460993 loss: 0.8271344900131226\n",
      "61: accuracy:0.22695035460992907 loss: 0.9358357191085815\n",
      "62: accuracy:0.24113475177304963 loss: 0.8618905544281006\n",
      "63: accuracy:0.23404255319148937 loss: 0.7295676469802856\n",
      "64: accuracy:0.2624113475177305 loss: 0.8764564394950867\n",
      "65: accuracy:0.2695035460992908 loss: 0.6280040740966797\n",
      "66: accuracy:0.2907801418439716 loss: 0.6450210213661194\n",
      "67: accuracy:0.2907801418439716 loss: 0.5949377417564392\n",
      "68: accuracy:0.2624113475177305 loss: 0.7616645693778992\n",
      "69: accuracy:0.24822695035460993 loss: 0.7862473130226135\n",
      "70: accuracy:0.2695035460992908 loss: 1.0785995721817017\n",
      "71: accuracy:0.2553191489361702 loss: 1.1152706146240234\n",
      "72: accuracy:0.28368794326241137 loss: 1.011225938796997\n",
      "73: accuracy:0.2624113475177305 loss: 0.7269079685211182\n",
      "74: accuracy:0.2624113475177305 loss: 0.9550989270210266\n",
      "75: accuracy:0.2624113475177305 loss: 0.7841989398002625\n",
      "76: accuracy:0.2695035460992908 loss: 0.7884467244148254\n",
      "77: accuracy:0.2695035460992908 loss: 0.4932710826396942\n",
      "78: accuracy:0.2553191489361702 loss: 0.7097427248954773\n",
      "79: accuracy:0.2553191489361702 loss: 0.6618712544441223\n",
      "80: accuracy:0.2765957446808511 loss: 0.7096633911132812\n",
      "81: accuracy:0.2765957446808511 loss: 0.545323371887207\n",
      "82: accuracy:0.28368794326241137 loss: 0.6771617531776428\n",
      "83: accuracy:0.2907801418439716 loss: 0.835271954536438\n",
      "84: accuracy:0.3049645390070922 loss: 0.8939517140388489\n",
      "85: accuracy:0.3049645390070922 loss: 0.6196704506874084\n",
      "86: accuracy:0.3049645390070922 loss: 0.7424649000167847\n",
      "87: accuracy:0.3120567375886525 loss: 0.6487783789634705\n",
      "88: accuracy:0.3120567375886525 loss: 0.7787813544273376\n",
      "89: accuracy:0.2907801418439716 loss: 0.6322852373123169\n",
      "90: accuracy:0.2978723404255319 loss: 0.7446455359458923\n",
      "91: accuracy:0.28368794326241137 loss: 0.6964823603630066\n",
      "92: accuracy:0.2907801418439716 loss: 0.6488827466964722\n",
      "93: accuracy:0.2978723404255319 loss: 0.5932011604309082\n",
      "94: accuracy:0.2978723404255319 loss: 0.666594386100769\n",
      "95: accuracy:0.2978723404255319 loss: 0.642882227897644\n",
      "96: accuracy:0.2907801418439716 loss: 0.5936800837516785\n",
      "97: accuracy:0.28368794326241137 loss: 0.7038004398345947\n",
      "98: accuracy:0.28368794326241137 loss: 0.5984932780265808\n",
      "99: accuracy:0.2907801418439716 loss: 0.5714800953865051\n",
      "100: accuracy:0.3049645390070922 loss: 0.6748612523078918\n",
      "101: accuracy:0.28368794326241137 loss: 0.532561719417572\n",
      "102: accuracy:0.2765957446808511 loss: 0.4766208529472351\n",
      "103: accuracy:0.2695035460992908 loss: 0.6125510334968567\n",
      "104: accuracy:0.2624113475177305 loss: 0.5098045468330383\n",
      "105: accuracy:0.2765957446808511 loss: 0.4076816141605377\n",
      "106: accuracy:0.2553191489361702 loss: 0.5885445475578308\n",
      "107: accuracy:0.2198581560283688 loss: 0.48829296231269836\n",
      "108: accuracy:0.2553191489361702 loss: 0.4384032189846039\n",
      "109: accuracy:0.19858156028368795 loss: 0.5004423260688782\n",
      "110: accuracy:0.2127659574468085 loss: 0.405539333820343\n",
      "111: accuracy:0.2198581560283688 loss: 0.3181416094303131\n",
      "112: accuracy:0.18439716312056736 loss: 0.44257569313049316\n",
      "113: accuracy:0.23404255319148937 loss: 0.34216174483299255\n",
      "114: accuracy:0.2624113475177305 loss: 0.568168044090271\n",
      "115: accuracy:0.2624113475177305 loss: 0.2612188756465912\n",
      "116: accuracy:0.24822695035460993 loss: 0.2595091462135315\n",
      "117: accuracy:0.2127659574468085 loss: 0.328521192073822\n",
      "118: accuracy:0.2127659574468085 loss: 0.2792051434516907\n",
      "119: accuracy:0.23404255319148937 loss: 0.29666629433631897\n",
      "120: accuracy:0.2624113475177305 loss: 0.34804946184158325\n",
      "121: accuracy:0.24822695035460993 loss: 0.22179685533046722\n",
      "122: accuracy:0.22695035460992907 loss: 0.13302315771579742\n",
      "123: accuracy:0.24822695035460993 loss: 0.19089920818805695\n",
      "124: accuracy:0.23404255319148937 loss: 0.2381444126367569\n",
      "125: accuracy:0.24822695035460993 loss: 0.06081743910908699\n",
      "126: accuracy:0.2624113475177305 loss: 0.07809973508119583\n",
      "127: accuracy:0.24113475177304963 loss: 0.05386616662144661\n",
      "128: accuracy:0.24113475177304963 loss: 0.06109442189335823\n",
      "129: accuracy:0.2553191489361702 loss: 0.1993766725063324\n",
      "130: accuracy:0.2624113475177305 loss: 0.06766799837350845\n",
      "131: accuracy:0.2978723404255319 loss: 0.2253129482269287\n",
      "132: accuracy:0.28368794326241137 loss: 0.0712813287973404\n",
      "133: accuracy:0.2624113475177305 loss: 0.14554144442081451\n",
      "134: accuracy:0.2695035460992908 loss: 0.051236677914857864\n",
      "135: accuracy:0.2695035460992908 loss: 0.029476193711161613\n",
      "136: accuracy:0.2907801418439716 loss: 0.08566547185182571\n",
      "137: accuracy:0.2695035460992908 loss: 0.10773123055696487\n",
      "138: accuracy:0.2765957446808511 loss: 0.1785660684108734\n",
      "139: accuracy:0.2553191489361702 loss: 0.17607413232326508\n",
      "140: accuracy:0.24822695035460993 loss: 0.42872411012649536\n",
      "141: accuracy:0.24822695035460993 loss: 0.320436954498291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142: accuracy:0.23404255319148937 loss: 0.22720927000045776\n",
      "143: accuracy:0.2765957446808511 loss: 0.12546999752521515\n",
      "144: accuracy:0.24113475177304963 loss: 0.457686185836792\n",
      "145: accuracy:0.2907801418439716 loss: 0.1770227551460266\n",
      "146: accuracy:0.2765957446808511 loss: 0.05575019121170044\n",
      "147: accuracy:0.28368794326241137 loss: 0.10316809266805649\n",
      "148: accuracy:0.2695035460992908 loss: 0.1405351310968399\n",
      "149: accuracy:0.2624113475177305 loss: 0.09492642432451248\n",
      "150: accuracy:0.2907801418439716 loss: 0.057461269199848175\n",
      "151: accuracy:0.2978723404255319 loss: 0.05150166153907776\n",
      "152: accuracy:0.3120567375886525 loss: 0.09667906910181046\n",
      "153: accuracy:0.2907801418439716 loss: 0.03867962583899498\n",
      "154: accuracy:0.2978723404255319 loss: 0.10656842589378357\n",
      "155: accuracy:0.2553191489361702 loss: 0.565399169921875\n",
      "156: accuracy:0.24113475177304963 loss: 0.6753730773925781\n",
      "157: accuracy:0.2553191489361702 loss: 0.6518615484237671\n",
      "158: accuracy:0.2198581560283688 loss: 0.5570526123046875\n",
      "159: accuracy:0.2198581560283688 loss: 0.6518135070800781\n",
      "160: accuracy:0.24822695035460993 loss: 0.3067878484725952\n",
      "161: accuracy:0.2765957446808511 loss: 0.11397718638181686\n",
      "162: accuracy:0.2695035460992908 loss: 0.11651591956615448\n",
      "163: accuracy:0.2624113475177305 loss: 0.10418929159641266\n",
      "164: accuracy:0.2553191489361702 loss: 0.13827307522296906\n",
      "165: accuracy:0.24822695035460993 loss: 0.027079056948423386\n",
      "166: accuracy:0.23404255319148937 loss: 0.03496108204126358\n",
      "167: accuracy:0.22695035460992907 loss: 0.02911987341940403\n",
      "168: accuracy:0.22695035460992907 loss: 0.01890294812619686\n",
      "169: accuracy:0.2127659574468085 loss: 0.02668018266558647\n",
      "170: accuracy:0.2127659574468085 loss: 0.015141984447836876\n",
      "171: accuracy:0.2127659574468085 loss: 0.011154365725815296\n",
      "172: accuracy:0.20567375886524822 loss: 0.006725706160068512\n",
      "173: accuracy:0.20567375886524822 loss: 0.011778416112065315\n",
      "174: accuracy:0.20567375886524822 loss: 0.009547029621899128\n",
      "175: accuracy:0.20567375886524822 loss: 0.008776173926889896\n",
      "176: accuracy:0.2198581560283688 loss: 0.005143356509506702\n",
      "177: accuracy:0.2198581560283688 loss: 0.005255658179521561\n",
      "178: accuracy:0.22695035460992907 loss: 0.0043049948289990425\n",
      "179: accuracy:0.22695035460992907 loss: 0.004145581275224686\n",
      "180: accuracy:0.22695035460992907 loss: 0.004877178929746151\n",
      "181: accuracy:0.22695035460992907 loss: 0.005115550011396408\n",
      "182: accuracy:0.22695035460992907 loss: 0.0044581275433301926\n",
      "183: accuracy:0.22695035460992907 loss: 0.0058702402748167515\n",
      "184: accuracy:0.22695035460992907 loss: 0.00428706593811512\n",
      "185: accuracy:0.22695035460992907 loss: 0.004960332531481981\n",
      "186: accuracy:0.23404255319148937 loss: 0.00324249267578125\n",
      "187: accuracy:0.23404255319148937 loss: 0.00442826421931386\n",
      "188: accuracy:0.23404255319148937 loss: 0.003258493961766362\n",
      "189: accuracy:0.23404255319148937 loss: 0.0027748243883252144\n",
      "190: accuracy:0.23404255319148937 loss: 0.0037392480298876762\n",
      "191: accuracy:0.23404255319148937 loss: 0.004339994862675667\n",
      "192: accuracy:0.23404255319148937 loss: 0.0023524966090917587\n",
      "193: accuracy:0.23404255319148937 loss: 0.0028455257415771484\n",
      "194: accuracy:0.23404255319148937 loss: 0.002953113755211234\n",
      "195: accuracy:0.23404255319148937 loss: 0.0024093899410218\n",
      "196: accuracy:0.23404255319148937 loss: 0.0023924419656395912\n",
      "197: accuracy:0.23404255319148937 loss: 0.002433511195704341\n",
      "198: accuracy:0.23404255319148937 loss: 0.0026595115195959806\n",
      "199: accuracy:0.23404255319148937 loss: 0.002394383307546377\n",
      "200: accuracy:0.23404255319148937 loss: 0.0024791036266833544\n",
      "201: accuracy:0.23404255319148937 loss: 0.001888929051347077\n",
      "202: accuracy:0.23404255319148937 loss: 0.0016877719899639487\n",
      "203: accuracy:0.23404255319148937 loss: 0.0019295010715723038\n",
      "204: accuracy:0.23404255319148937 loss: 0.0019541603978723288\n",
      "205: accuracy:0.23404255319148937 loss: 0.0018194335279986262\n",
      "206: accuracy:0.23404255319148937 loss: 0.0018990789540112019\n",
      "207: accuracy:0.23404255319148937 loss: 0.0016961029032245278\n",
      "208: accuracy:0.23404255319148937 loss: 0.0019594738259911537\n",
      "209: accuracy:0.23404255319148937 loss: 0.0020855357870459557\n",
      "210: accuracy:0.23404255319148937 loss: 0.0021816594526171684\n",
      "211: accuracy:0.23404255319148937 loss: 0.001405586488544941\n",
      "212: accuracy:0.23404255319148937 loss: 0.001728323521092534\n",
      "213: accuracy:0.23404255319148937 loss: 0.0011233602417632937\n",
      "214: accuracy:0.23404255319148937 loss: 0.001823050668463111\n",
      "215: accuracy:0.23404255319148937 loss: 0.0013977119233459234\n",
      "216: accuracy:0.23404255319148937 loss: 0.0015555790159851313\n",
      "217: accuracy:0.23404255319148937 loss: 0.0012396404054015875\n",
      "218: accuracy:0.23404255319148937 loss: 0.0014468737645074725\n",
      "219: accuracy:0.23404255319148937 loss: 0.002029269002377987\n",
      "220: accuracy:0.23404255319148937 loss: 0.0017773219151422381\n",
      "221: accuracy:0.23404255319148937 loss: 0.0016945021925494075\n",
      "222: accuracy:0.23404255319148937 loss: 0.0011128834448754787\n",
      "223: accuracy:0.23404255319148937 loss: 0.0014153888914734125\n",
      "224: accuracy:0.23404255319148937 loss: 0.0016651698388159275\n",
      "225: accuracy:0.23404255319148937 loss: 0.00115085334982723\n",
      "226: accuracy:0.23404255319148937 loss: 0.0018212726572528481\n",
      "227: accuracy:0.23404255319148937 loss: 0.00125003547873348\n",
      "228: accuracy:0.23404255319148937 loss: 0.001242835191078484\n",
      "229: accuracy:0.24113475177304963 loss: 0.0011970383347943425\n",
      "230: accuracy:0.24113475177304963 loss: 0.0012513977708294988\n",
      "231: accuracy:0.24113475177304963 loss: 0.0015031882794573903\n",
      "232: accuracy:0.24113475177304963 loss: 0.0009621756616979837\n",
      "233: accuracy:0.24113475177304963 loss: 0.0015198298497125506\n",
      "234: accuracy:0.24113475177304963 loss: 0.0015174048021435738\n",
      "235: accuracy:0.24113475177304963 loss: 0.0010175841161981225\n",
      "236: accuracy:0.24113475177304963 loss: 0.0010638645617291331\n",
      "237: accuracy:0.24113475177304963 loss: 0.0011028562439605594\n",
      "238: accuracy:0.23404255319148937 loss: 0.0010423115454614162\n",
      "239: accuracy:0.24113475177304963 loss: 0.0007772445678710938\n",
      "240: accuracy:0.23404255319148937 loss: 0.0010120663791894913\n",
      "241: accuracy:0.23404255319148937 loss: 0.0015062604798004031\n",
      "242: accuracy:0.23404255319148937 loss: 0.001221411512233317\n",
      "243: accuracy:0.23404255319148937 loss: 0.0010039056651294231\n",
      "244: accuracy:0.23404255319148937 loss: 0.0010801451280713081\n",
      "245: accuracy:0.23404255319148937 loss: 0.0007955006440170109\n",
      "246: accuracy:0.23404255319148937 loss: 0.000828756601549685\n",
      "247: accuracy:0.24113475177304963 loss: 0.0006392615032382309\n",
      "248: accuracy:0.24113475177304963 loss: 0.001055485918186605\n",
      "249: accuracy:0.24113475177304963 loss: 0.0013624735875055194\n",
      "250: accuracy:0.24113475177304963 loss: 0.0008915219805203378\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = RNN_old()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "for epoch in range(1,251): \n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        pred = net(batch_x)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_e)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-new 0.6737588652482269 17轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "MAX_LENGTH = 53\n",
    "for i in range(0,467):\n",
    "    a = np.loadtxt('/Users/denhiroshi/Downloads/Embeding/ans_1.0_'+str(i)+'.csv',dtype=np.float64,delimiter=',')\n",
    "    a = a.transpose(1,0)\n",
    "    a = np.exp(a)\n",
    "    a = np.sum(a,axis=1)\n",
    "    a = np.log(a)\n",
    "    if a.shape[0] < MAX_LENGTH:\n",
    "        add = MAX_LENGTH - a.shape[0]\n",
    "        adds = np.zeros(add)\n",
    "        a = np.concatenate((a, adds))\n",
    "    inputs.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = np.stack(inputs)\n",
    "mean = use.mean()         #计算平均数\n",
    "deviation = use.std()     #计算标准差\n",
    "# 标准化数据的公式: (数据值 - 平均数) / 标准差\n",
    "use = (use - mean) / deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.fromfile('glove_WV.dat',dtype=np.float64).reshape((467,-1,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((467, 53, 200), (467, 53))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape,use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(467):\n",
    "    inputs.append((torch.from_numpy(b[i]),torch.from_numpy(use[i]),Y[i]))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([141, 53]), torch.Size([141, 53, 200]), torch.Size([141]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = []\n",
    "t_e = []\n",
    "t_y = []\n",
    "for E,S,Y in test:\n",
    "    t_s.append(S)\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "t_s = torch.stack(t_s)\n",
    "t_e = torch.stack(t_e)\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_s.shape, t_e.shape, t_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size = 200,       # rnn input\n",
    "            hidden_size = 64,     # rnn hidden unit\n",
    "            num_layers = 1,       # 有几层 RNN layers\n",
    "            batch_first=True,   # input & output 会是以 batch size 为第一维度的特征集 e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "        self.out=torch.nn.Linear(in_features=65 ,out_features=7)\n",
    "        self.maxpool = torch.nn.MaxPool2d((53,1))\n",
    "\n",
    "    def forward(self,sen,x):\n",
    "        output,h_n=self.rnn(x.float())\n",
    "        sen = sen.reshape((sen.shape[0],sen.shape[1],1))  # (BATCH_SIZE,53,1)\n",
    "        output1 = torch.bmm(torch.transpose(output,1,2).float(),sen.float())  # (BATCH_SIZE,64,1)\n",
    "        output1 = torch.sigmoid(output1)\n",
    "        output1 = torch.softmax(output1,1)\n",
    "        output1 = torch.bmm(output,output1) # (BATCH_SIZE,53,1)\n",
    "        output = torch.cat((output1,output),2) # (BATCH_SIZE,53,65)\n",
    "        output = self.maxpool(output)   # (BATCH_SIZE,1,65)\n",
    "        output = output.reshape((output.shape[0],-1)) # (BATCH_SIZE,7)\n",
    "        x1 = self.out(output.float())\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): GRU(200, 64, batch_first=True)\n",
      "  (out): Linear(in_features=65, out_features=7, bias=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=(53, 1), stride=(53, 1), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "1: accuracy:0.2695035460992908 loss: 1.9541912078857422\n",
      "2: accuracy:0.3900709219858156 loss: 1.772621750831604\n",
      "3: accuracy:0.3333333333333333 loss: 1.606994390487671\n",
      "4: accuracy:0.4326241134751773 loss: 1.4174365997314453\n",
      "5: accuracy:0.5177304964539007 loss: 1.2522685527801514\n",
      "6: accuracy:0.5673758865248227 loss: 1.1295371055603027\n",
      "7: accuracy:0.5531914893617021 loss: 0.9108871817588806\n",
      "8: accuracy:0.6028368794326241 loss: 0.7546970844268799\n",
      "9: accuracy:0.574468085106383 loss: 0.5393237471580505\n",
      "10: accuracy:0.6170212765957447 loss: 0.4772818088531494\n",
      "11: accuracy:0.624113475177305 loss: 0.37971144914627075\n",
      "12: accuracy:0.6312056737588653 loss: 0.25231868028640747\n",
      "13: accuracy:0.6312056737588653 loss: 0.18982568383216858\n",
      "14: accuracy:0.6382978723404256 loss: 0.11684030294418335\n",
      "15: accuracy:0.6099290780141844 loss: 0.10033412277698517\n",
      "16: accuracy:0.6453900709219859 loss: 0.07209061086177826\n",
      "17: accuracy:0.6737588652482269 loss: 0.05450940877199173\n",
      "18: accuracy:0.6524822695035462 loss: 0.03416745364665985\n",
      "19: accuracy:0.6453900709219859 loss: 0.025624504312872887\n",
      "20: accuracy:0.6453900709219859 loss: 0.020326849073171616\n",
      "21: accuracy:0.6524822695035462 loss: 0.015299282968044281\n",
      "22: accuracy:0.6382978723404256 loss: 0.012985123321413994\n",
      "23: accuracy:0.6382978723404256 loss: 0.012228613719344139\n",
      "24: accuracy:0.6453900709219859 loss: 0.009806431829929352\n",
      "25: accuracy:0.6382978723404256 loss: 0.007394365966320038\n",
      "26: accuracy:0.6524822695035462 loss: 0.023011013865470886\n",
      "27: accuracy:0.6595744680851063 loss: 0.005586275830864906\n",
      "28: accuracy:0.6524822695035462 loss: 0.005437813699245453\n",
      "29: accuracy:0.6524822695035462 loss: 0.005268530920147896\n",
      "30: accuracy:0.6382978723404256 loss: 0.0050008296966552734\n",
      "31: accuracy:0.6382978723404256 loss: 0.004099611192941666\n",
      "32: accuracy:0.6453900709219859 loss: 0.004479538649320602\n",
      "33: accuracy:0.6382978723404256 loss: 0.0036450400948524475\n",
      "34: accuracy:0.6382978723404256 loss: 0.0032815076410770416\n",
      "35: accuracy:0.6312056737588653 loss: 0.0031014420092105865\n",
      "36: accuracy:0.6453900709219859 loss: 0.0026360228657722473\n",
      "37: accuracy:0.6382978723404256 loss: 0.002539433538913727\n",
      "38: accuracy:0.6382978723404256 loss: 0.0027378909289836884\n",
      "39: accuracy:0.6524822695035462 loss: 0.0023946426808834076\n",
      "40: accuracy:0.6524822695035462 loss: 0.0022426769137382507\n",
      "41: accuracy:0.6595744680851063 loss: 0.002091839909553528\n",
      "42: accuracy:0.6595744680851063 loss: 0.0021924450993537903\n",
      "43: accuracy:0.6595744680851063 loss: 0.0020485669374465942\n",
      "44: accuracy:0.6524822695035462 loss: 0.001966126263141632\n",
      "45: accuracy:0.6524822695035462 loss: 0.001816626638174057\n",
      "46: accuracy:0.6524822695035462 loss: 0.0018643513321876526\n",
      "47: accuracy:0.6524822695035462 loss: 0.0017486922442913055\n",
      "48: accuracy:0.6453900709219859 loss: 0.0019716545939445496\n",
      "49: accuracy:0.6453900709219859 loss: 0.0020803920924663544\n",
      "50: accuracy:0.6453900709219859 loss: 0.0016222521662712097\n",
      "51: accuracy:0.6453900709219859 loss: 0.0017589479684829712\n",
      "52: accuracy:0.6524822695035462 loss: 0.001497700810432434\n",
      "53: accuracy:0.6524822695035462 loss: 0.0014972537755966187\n",
      "54: accuracy:0.6524822695035462 loss: 0.0014978386461734772\n",
      "55: accuracy:0.6453900709219859 loss: 0.0015304386615753174\n",
      "56: accuracy:0.6382978723404256 loss: 0.0016073733568191528\n",
      "57: accuracy:0.6312056737588653 loss: 0.0016477778553962708\n",
      "58: accuracy:0.6312056737588653 loss: 0.0013682655990123749\n",
      "59: accuracy:0.6312056737588653 loss: 0.0014086253941059113\n",
      "60: accuracy:0.6453900709219859 loss: 0.001437649130821228\n",
      "61: accuracy:0.6453900709219859 loss: 0.0013026036322116852\n",
      "62: accuracy:0.6453900709219859 loss: 0.0010991394519805908\n",
      "63: accuracy:0.6453900709219859 loss: 0.0012199953198432922\n",
      "64: accuracy:0.6453900709219859 loss: 0.0013217441737651825\n",
      "65: accuracy:0.6453900709219859 loss: 0.0013141520321369171\n",
      "66: accuracy:0.6453900709219859 loss: 0.001140505075454712\n",
      "67: accuracy:0.6382978723404256 loss: 0.0010871216654777527\n",
      "68: accuracy:0.6382978723404256 loss: 0.0012781359255313873\n",
      "69: accuracy:0.6382978723404256 loss: 0.0011217035353183746\n",
      "70: accuracy:0.6453900709219859 loss: 0.0009665563702583313\n",
      "71: accuracy:0.6453900709219859 loss: 0.0012790821492671967\n",
      "72: accuracy:0.6453900709219859 loss: 0.0011628605425357819\n",
      "73: accuracy:0.6453900709219859 loss: 0.0011135190725326538\n",
      "74: accuracy:0.6453900709219859 loss: 0.0010425783693790436\n",
      "75: accuracy:0.6453900709219859 loss: 0.0010488219559192657\n",
      "76: accuracy:0.6453900709219859 loss: 0.000896647572517395\n",
      "77: accuracy:0.6453900709219859 loss: 0.0009616315364837646\n",
      "78: accuracy:0.6453900709219859 loss: 0.0009283311665058136\n",
      "79: accuracy:0.6453900709219859 loss: 0.0008399747312068939\n",
      "80: accuracy:0.6453900709219859 loss: 0.000909656286239624\n",
      "81: accuracy:0.6453900709219859 loss: 0.0009126476943492889\n",
      "82: accuracy:0.6453900709219859 loss: 0.0008199475705623627\n",
      "83: accuracy:0.6453900709219859 loss: 0.0009473450481891632\n",
      "84: accuracy:0.6453900709219859 loss: 0.0009251013398170471\n",
      "85: accuracy:0.6453900709219859 loss: 0.0009229220449924469\n",
      "86: accuracy:0.6453900709219859 loss: 0.0007088668644428253\n",
      "87: accuracy:0.6453900709219859 loss: 0.0007070079445838928\n",
      "88: accuracy:0.6453900709219859 loss: 0.0008158385753631592\n",
      "89: accuracy:0.6453900709219859 loss: 0.0009458214044570923\n",
      "90: accuracy:0.6453900709219859 loss: 0.0008577294647693634\n",
      "91: accuracy:0.6453900709219859 loss: 0.000712420791387558\n",
      "92: accuracy:0.6453900709219859 loss: 0.0007322579622268677\n",
      "93: accuracy:0.6453900709219859 loss: 0.000704057514667511\n",
      "94: accuracy:0.6453900709219859 loss: 0.0006478205323219299\n",
      "95: accuracy:0.6453900709219859 loss: 0.0007864460349082947\n",
      "96: accuracy:0.6453900709219859 loss: 0.0006579384207725525\n",
      "97: accuracy:0.6453900709219859 loss: 0.0008106231689453125\n",
      "98: accuracy:0.6453900709219859 loss: 0.0007355883717536926\n",
      "99: accuracy:0.6453900709219859 loss: 0.0007903911173343658\n",
      "100: accuracy:0.6453900709219859 loss: 0.0006497763097286224\n",
      "101: accuracy:0.6453900709219859 loss: 0.0007098168134689331\n",
      "102: accuracy:0.6453900709219859 loss: 0.000749979168176651\n",
      "103: accuracy:0.6453900709219859 loss: 0.000613287091255188\n",
      "104: accuracy:0.6453900709219859 loss: 0.0006865337491035461\n",
      "105: accuracy:0.6524822695035462 loss: 0.0005539692938327789\n",
      "106: accuracy:0.6524822695035462 loss: 0.0006400160491466522\n",
      "107: accuracy:0.6524822695035462 loss: 0.0006059780716896057\n",
      "108: accuracy:0.6524822695035462 loss: 0.000636804848909378\n",
      "109: accuracy:0.6453900709219859 loss: 0.0006522424519062042\n",
      "110: accuracy:0.6453900709219859 loss: 0.0005869269371032715\n",
      "111: accuracy:0.6453900709219859 loss: 0.0005461238324642181\n",
      "112: accuracy:0.6453900709219859 loss: 0.0006235130131244659\n",
      "113: accuracy:0.6453900709219859 loss: 0.000686008483171463\n",
      "114: accuracy:0.6382978723404256 loss: 0.0005885213613510132\n",
      "115: accuracy:0.6382978723404256 loss: 0.0005823522806167603\n",
      "116: accuracy:0.6453900709219859 loss: 0.0005035251379013062\n",
      "117: accuracy:0.6453900709219859 loss: 0.0005701594054698944\n",
      "118: accuracy:0.6453900709219859 loss: 0.0004726238548755646\n",
      "119: accuracy:0.6453900709219859 loss: 0.000547405332326889\n",
      "120: accuracy:0.6453900709219859 loss: 0.0006389915943145752\n",
      "121: accuracy:0.6382978723404256 loss: 0.0005852058529853821\n",
      "122: accuracy:0.6382978723404256 loss: 0.0006023980677127838\n",
      "123: accuracy:0.6382978723404256 loss: 0.0005347020924091339\n",
      "124: accuracy:0.6312056737588653 loss: 0.0005143508315086365\n",
      "125: accuracy:0.6312056737588653 loss: 0.0005027018487453461\n",
      "126: accuracy:0.6312056737588653 loss: 0.0005009286105632782\n",
      "127: accuracy:0.6312056737588653 loss: 0.0004614144563674927\n",
      "128: accuracy:0.6312056737588653 loss: 0.0004107840359210968\n",
      "129: accuracy:0.6312056737588653 loss: 0.0005002692341804504\n",
      "130: accuracy:0.6312056737588653 loss: 0.0005281604826450348\n",
      "131: accuracy:0.6312056737588653 loss: 0.000498652458190918\n",
      "132: accuracy:0.6312056737588653 loss: 0.0004076436161994934\n",
      "133: accuracy:0.6312056737588653 loss: 0.00047869980335235596\n",
      "134: accuracy:0.6312056737588653 loss: 0.0005404055118560791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135: accuracy:0.6312056737588653 loss: 0.0005545839667320251\n",
      "136: accuracy:0.6312056737588653 loss: 0.00046394020318984985\n",
      "137: accuracy:0.6382978723404256 loss: 0.0004654601216316223\n",
      "138: accuracy:0.6382978723404256 loss: 0.00037739425897598267\n",
      "139: accuracy:0.6382978723404256 loss: 0.0004795156419277191\n",
      "140: accuracy:0.6382978723404256 loss: 0.0004212707281112671\n",
      "141: accuracy:0.6382978723404256 loss: 0.0005138963460922241\n",
      "142: accuracy:0.6382978723404256 loss: 0.00042288750410079956\n",
      "143: accuracy:0.6382978723404256 loss: 0.00043049082159996033\n",
      "144: accuracy:0.6382978723404256 loss: 0.000390518456697464\n",
      "145: accuracy:0.6382978723404256 loss: 0.0003867931663990021\n",
      "146: accuracy:0.6382978723404256 loss: 0.00042531639337539673\n",
      "147: accuracy:0.6382978723404256 loss: 0.00036405399441719055\n",
      "148: accuracy:0.6382978723404256 loss: 0.00033909454941749573\n",
      "149: accuracy:0.6382978723404256 loss: 0.00040668994188308716\n",
      "150: accuracy:0.6382978723404256 loss: 0.00033704936504364014\n",
      "151: accuracy:0.6382978723404256 loss: 0.0003558211028575897\n",
      "152: accuracy:0.6382978723404256 loss: 0.0004135817289352417\n",
      "153: accuracy:0.6312056737588653 loss: 0.00033346936106681824\n",
      "154: accuracy:0.6312056737588653 loss: 0.0003212094306945801\n",
      "155: accuracy:0.6312056737588653 loss: 0.0003913380205631256\n",
      "156: accuracy:0.6312056737588653 loss: 0.0003685951232910156\n",
      "157: accuracy:0.6312056737588653 loss: 0.0003195442259311676\n",
      "158: accuracy:0.6312056737588653 loss: 0.0004136301577091217\n",
      "159: accuracy:0.6382978723404256 loss: 0.00035689398646354675\n",
      "160: accuracy:0.6382978723404256 loss: 0.0003869868814945221\n",
      "161: accuracy:0.6382978723404256 loss: 0.000354226678609848\n",
      "162: accuracy:0.6382978723404256 loss: 0.0003445819020271301\n",
      "163: accuracy:0.6382978723404256 loss: 0.000332564115524292\n",
      "164: accuracy:0.6382978723404256 loss: 0.0003206506371498108\n",
      "165: accuracy:0.6382978723404256 loss: 0.00038226693868637085\n",
      "166: accuracy:0.6312056737588653 loss: 0.000359315425157547\n",
      "167: accuracy:0.6312056737588653 loss: 0.00034715980291366577\n",
      "168: accuracy:0.6312056737588653 loss: 0.0003042668104171753\n",
      "169: accuracy:0.6312056737588653 loss: 0.00030785053968429565\n",
      "170: accuracy:0.6312056737588653 loss: 0.0003606453537940979\n",
      "171: accuracy:0.6312056737588653 loss: 0.0002716854214668274\n",
      "172: accuracy:0.6312056737588653 loss: 0.00033744052052497864\n",
      "173: accuracy:0.6312056737588653 loss: 0.0003258734941482544\n",
      "174: accuracy:0.6312056737588653 loss: 0.00029391422867774963\n",
      "175: accuracy:0.6312056737588653 loss: 0.00035595521330833435\n",
      "176: accuracy:0.6312056737588653 loss: 0.0002869553864002228\n",
      "177: accuracy:0.6312056737588653 loss: 0.0002927333116531372\n",
      "178: accuracy:0.6312056737588653 loss: 0.0002942308783531189\n",
      "179: accuracy:0.6312056737588653 loss: 0.00033984333276748657\n",
      "180: accuracy:0.6312056737588653 loss: 0.00028996914625167847\n",
      "181: accuracy:0.6312056737588653 loss: 0.00027012452483177185\n",
      "182: accuracy:0.6312056737588653 loss: 0.00032458454370498657\n",
      "183: accuracy:0.6312056737588653 loss: 0.00028292834758758545\n",
      "184: accuracy:0.6312056737588653 loss: 0.0003310069441795349\n",
      "185: accuracy:0.6312056737588653 loss: 0.00031556934118270874\n",
      "186: accuracy:0.6312056737588653 loss: 0.0003215372562408447\n",
      "187: accuracy:0.6312056737588653 loss: 0.0003068596124649048\n",
      "188: accuracy:0.6312056737588653 loss: 0.00032820925116539\n",
      "189: accuracy:0.6312056737588653 loss: 0.00024910271167755127\n",
      "190: accuracy:0.6312056737588653 loss: 0.0003098025918006897\n",
      "191: accuracy:0.6312056737588653 loss: 0.00024058297276496887\n",
      "192: accuracy:0.6312056737588653 loss: 0.0002310723066329956\n",
      "193: accuracy:0.6312056737588653 loss: 0.0002931654453277588\n",
      "194: accuracy:0.6312056737588653 loss: 0.00026369839906692505\n",
      "195: accuracy:0.6312056737588653 loss: 0.0003244951367378235\n",
      "196: accuracy:0.6312056737588653 loss: 0.00028672441840171814\n",
      "197: accuracy:0.6312056737588653 loss: 0.00029192864894866943\n",
      "198: accuracy:0.6312056737588653 loss: 0.00026096031069755554\n",
      "199: accuracy:0.6312056737588653 loss: 0.00026721134781837463\n",
      "200: accuracy:0.6312056737588653 loss: 0.00027931109070777893\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    "    drop_last=True,\n",
    ")\n",
    "net = RNN()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "for epoch in range(1,201): \n",
    "    for step, (batch_x, sen, batch_y) in enumerate(loader):\n",
    "        pred = net(sen, batch_x)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 1: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_s, t_e)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
