{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function set_backend in module tensorly:\n",
      "\n",
      "set_backend(backend_name)\n",
      "    Sets the backend for TensorLy\n",
      "    \n",
      "        The backend will be set as specified and operations will used that backend\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    backend_name : {'mxnet', 'numpy', 'pytorch', 'tensorflow', 'cupy'}, default is 'numpy'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 128\n",
    "tl.set_backend('pytorch')\n",
    "help(tl.set_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467,)\n"
     ]
    }
   ],
   "source": [
    "tag = [72, 71, 84, 54, 57, 65, 64]\n",
    "Y = np.zeros(467)\n",
    "print(Y.shape)\n",
    "Y[0 : tag[0]] = 0\n",
    "Y[tag[0] : tag[0]+tag[1]] = 1\n",
    "Y[tag[0]+tag[1] : tag[0]+tag[1]+tag[2]] = 2\n",
    "Y[tag[0]+tag[1]+tag[2] : tag[0]+tag[1]+tag[2]+tag[3]] = 3\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]] = 4\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]] = 5\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]+tag[6]] = 6\n",
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "MAX_LENGTH = 53\n",
    "for i in range(0,467):\n",
    "    a = np.loadtxt('/Users/denhiroshi/Downloads/Embeding/ans_1.0_'+str(i)+'.csv',dtype=np.float64,delimiter=',')\n",
    "    a = a.transpose(1,0)\n",
    "    a = np.exp(a)\n",
    "    a = np.sum(a,axis=1)\n",
    "    a = np.log(a)\n",
    "    if a.shape[0] < MAX_LENGTH:\n",
    "        add = MAX_LENGTH - a.shape[0]\n",
    "        adds = np.zeros(add).astype(np.float64)\n",
    "        a = np.concatenate((a, adds))\n",
    "    inputs.append(a)\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = np.stack(inputs)\n",
    "mean = use.mean()         #计算平均数\n",
    "deviation = use.std()     #计算标准差\n",
    "# 标准化数据的公式: (数据值 - 平均数) / 标准差\n",
    "use = (use - mean) / deviation\n",
    "use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.fromfile('glove_WV.dat',dtype=np.float64).reshape((467,-1,200))\n",
    "position_tag = np.loadtxt('position_tag.csv',dtype=np.float64,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53, 202)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [i for i in range(53)]\n",
    "c = []\n",
    "for i in range(467):\n",
    "    position_a = (np.array(temp) - position_tag[i][0]).reshape((-1,1))\n",
    "    position_b = (np.array(temp) - position_tag[i][1]).reshape((-1,1))\n",
    "    position = np.concatenate((position_a,position_b),axis = 1)\n",
    "    c.append(np.concatenate((b[i],position),axis = 1))\n",
    "c = np.stack(c)\n",
    "b = c\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(467):\n",
    "    inputs.append((torch.from_numpy(b[i]),torch.from_numpy(use[i]),Y[i],position_tag[i].astype(np.int64)))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([141, 53]),\n",
       " torch.Size([141, 53, 202]),\n",
       " torch.Size([141]),\n",
       " torch.Size([141, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = []\n",
    "t_e = []\n",
    "t_y = []\n",
    "t_p = []\n",
    "\n",
    "for E,S,Y,pos in test:\n",
    "    t_s.append(S)\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "    t_p.append(pos)\n",
    "t_s = torch.stack(t_s)\n",
    "t_e = torch.stack(t_e)\n",
    "t_p = torch.from_numpy(np.stack(t_p))\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_s.shape, t_e.shape, t_y.shape, t_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.6170212765957447 23轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 53, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=53,    # n_filters\n",
    "                kernel_size=(1,202),      # filter size\n",
    "            ),      # output shape (16, 53, 200)\n",
    "            nn.ReLU(),    # activation\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(53,1))   # 在 2x2 空间里向下采样, output shape (16, 53, 1)\n",
    "        self.output = nn.Linear(159, 7)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x, pos):\n",
    "        torch.set_default_dtype(torch.double)\n",
    "        x = x.reshape((-1,1,53,202)).double()\n",
    "        x = self.conv1(x.double())\n",
    "        \n",
    "        x1 = torch.zeros(x.shape)\n",
    "        x2 = torch.zeros(x.shape)\n",
    "        x3 = torch.zeros(x.shape)\n",
    "        \n",
    "        min_x1 = torch.ones(x.shape) * (-100)\n",
    "        min_x2 = torch.ones(x.shape) * (-100)\n",
    "        min_x3 = torch.ones(x.shape) * (-100)\n",
    "        \n",
    "        for i in range(pos.shape[0]):\n",
    "            x1[i, :, :pos[i][0], :]\n",
    "            min_x1[i, :, :pos[i][0], :]  = 0.0\n",
    "            x2[i, :, pos[i][0]:pos[i][1], :]  = 1.0\n",
    "            min_x2[i, :, pos[i][0]:pos[i][1], :] = 0.0\n",
    "            x3[i, :, pos[i][1]:, :] = 1.0\n",
    "            min_x3[i, :, pos[i][1]:, :] = 0.0\n",
    "            \n",
    "         # 卷积结果*mask得到分段后的卷积向量\n",
    "        x1 *= x\n",
    "        x2 *= x\n",
    "        x3 *= x\n",
    "        \n",
    "        # 将无用部分赋予最小值，避免影响maxpool操作\n",
    "        x1 += min_x1\n",
    "        x2 += min_x2\n",
    "        x3 += min_x3\n",
    "        \n",
    "        # 分段池化\n",
    "        x1 = self.maxpool(x1)\n",
    "        x2 = self.maxpool(x2)\n",
    "        x3 = self.maxpool(x3)\n",
    "        \n",
    "        # 展平\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        \n",
    "        x = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 53, kernel_size=(1, 202), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=(53, 1), stride=(53, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (output): Linear(in_features=159, out_features=7, bias=True)\n",
      ")\n",
      "1: accuracy:0.23404255319148937 loss: 5.954211477863088 time: 0.28894901275634766\n",
      "2: accuracy:0.375886524822695 loss: 2.633158064424913 time: 0.5877439975738525\n",
      "3: accuracy:0.5531914893617021 loss: 5.8949285296198175 time: 0.8832509517669678\n",
      "4: accuracy:0.6028368794326241 loss: 0.931299924524409 time: 1.1701850891113281\n",
      "5: accuracy:0.6595744680851063 loss: 0.7485788800710669 time: 1.465142011642456\n",
      "6: accuracy:0.6808510638297872 loss: 0.5376507257038553 time: 1.7539260387420654\n",
      "7: accuracy:0.6950354609929078 loss: 1.943548238276211 time: 2.0485730171203613\n",
      "8: accuracy:0.6950354609929078 loss: 3.1755514603253636 time: 2.341400146484375\n",
      "9: accuracy:0.7092198581560284 loss: 0.4627722985149788 time: 2.634007215499878\n",
      "10: accuracy:0.6808510638297872 loss: 3.5100784424893425 time: 2.9202141761779785\n",
      "11: accuracy:0.6808510638297872 loss: 0.10675836880882798 time: 3.210319995880127\n",
      "12: accuracy:0.7021276595744681 loss: 1.9593286728801595 time: 3.502707004547119\n",
      "13: accuracy:0.6950354609929078 loss: 0.6520885884223951 time: 3.7888031005859375\n",
      "14: accuracy:0.6950354609929078 loss: 0.9952954998923019 time: 4.072530031204224\n",
      "15: accuracy:0.7092198581560284 loss: 0.3527706234100489 time: 4.366933107376099\n",
      "16: accuracy:0.6595744680851063 loss: 0.03115127134981317 time: 4.677385091781616\n",
      "17: accuracy:0.6595744680851063 loss: 1.1649638281652375 time: 4.98050594329834\n",
      "18: accuracy:0.7092198581560284 loss: 0.1785819673152313 time: 5.278640031814575\n",
      "19: accuracy:0.6737588652482269 loss: 0.09068436402939868 time: 5.588968992233276\n",
      "20: accuracy:0.624113475177305 loss: 0.06743585661232283 time: 5.931153059005737\n",
      "21: accuracy:0.6666666666666666 loss: 0.03430631529829576 time: 6.280040979385376\n",
      "22: accuracy:0.6808510638297872 loss: 0.02027070912500859 time: 6.617004156112671\n",
      "23: accuracy:0.7092198581560284 loss: 0.030346653454481082 time: 6.942821979522705\n",
      "24: accuracy:0.7092198581560284 loss: 0.0063758133644676515 time: 7.318219184875488\n",
      "25: accuracy:0.6950354609929078 loss: 0.004015454509963729 time: 7.639310836791992\n",
      "26: accuracy:0.6666666666666666 loss: 0.002199551623390139 time: 7.919394016265869\n",
      "27: accuracy:0.6879432624113475 loss: 0.002495529946429263 time: 8.203001260757446\n",
      "28: accuracy:0.6808510638297872 loss: 0.003051891567667285 time: 8.497430086135864\n",
      "29: accuracy:0.6808510638297872 loss: 0.001131147275493711 time: 8.794075965881348\n",
      "30: accuracy:0.6879432624113475 loss: 0.0031312731535075664 time: 9.082105875015259\n",
      "31: accuracy:0.6879432624113475 loss: 0.001246976564275602 time: 9.364295959472656\n",
      "32: accuracy:0.6879432624113475 loss: 0.001019691069217275 time: 9.650424242019653\n",
      "33: accuracy:0.6879432624113475 loss: 0.0010004160444655496 time: 9.958820104598999\n",
      "34: accuracy:0.6950354609929078 loss: 0.000613058263896057 time: 10.256484270095825\n",
      "35: accuracy:0.6950354609929078 loss: 0.0006930170831965502 time: 10.545250177383423\n",
      "36: accuracy:0.6950354609929078 loss: 0.0011281473217459822 time: 10.835161924362183\n",
      "37: accuracy:0.7021276595744681 loss: 0.000744271074235936 time: 11.12111496925354\n",
      "38: accuracy:0.7021276595744681 loss: 0.0009173153162843966 time: 11.400913000106812\n",
      "39: accuracy:0.7021276595744681 loss: 0.0006646145926165938 time: 11.686450958251953\n",
      "40: accuracy:0.7021276595744681 loss: 0.0009585213219968176 time: 11.987099885940552\n",
      "41: accuracy:0.6950354609929078 loss: 0.0008592414524803717 time: 12.289862871170044\n",
      "42: accuracy:0.6950354609929078 loss: 0.0007275144887645294 time: 12.591649055480957\n",
      "43: accuracy:0.6950354609929078 loss: 0.0006997293722637846 time: 12.904336929321289\n",
      "44: accuracy:0.6950354609929078 loss: 0.0005745010023948006 time: 13.196920156478882\n",
      "45: accuracy:0.6950354609929078 loss: 0.0005939880687593784 time: 13.479757070541382\n",
      "46: accuracy:0.6950354609929078 loss: 0.0004786429495694046 time: 13.764183044433594\n",
      "47: accuracy:0.6950354609929078 loss: 0.0003839291376993411 time: 14.057439088821411\n",
      "48: accuracy:0.6950354609929078 loss: 0.0005361974550101931 time: 14.35583209991455\n",
      "49: accuracy:0.6950354609929078 loss: 0.00043912355705217265 time: 14.663370132446289\n",
      "50: accuracy:0.6950354609929078 loss: 0.0005733487038769271 time: 14.946923017501831\n",
      "51: accuracy:0.6950354609929078 loss: 0.0004517040680595156 time: 15.252471208572388\n",
      "52: accuracy:0.7021276595744681 loss: 0.0004030993456168831 time: 15.547631978988647\n",
      "53: accuracy:0.7021276595744681 loss: 0.0004960768233615147 time: 15.855844974517822\n",
      "54: accuracy:0.7021276595744681 loss: 0.00038998679938434376 time: 16.17168426513672\n",
      "55: accuracy:0.7021276595744681 loss: 0.0005371214537994337 time: 16.459247827529907\n",
      "56: accuracy:0.7021276595744681 loss: 0.00043347109281901555 time: 16.74419617652893\n",
      "57: accuracy:0.7021276595744681 loss: 0.00041825758059532703 time: 17.034584045410156\n",
      "58: accuracy:0.7021276595744681 loss: 0.0004444481950780193 time: 17.323439121246338\n",
      "59: accuracy:0.7021276595744681 loss: 0.00042183382718339956 time: 17.610196113586426\n",
      "60: accuracy:0.7021276595744681 loss: 0.00032416025245962334 time: 17.8966121673584\n",
      "61: accuracy:0.7021276595744681 loss: 0.0004605262787046348 time: 18.186620950698853\n",
      "62: accuracy:0.7021276595744681 loss: 0.0004969213393748515 time: 18.474066019058228\n",
      "63: accuracy:0.7021276595744681 loss: 0.0002536990575164845 time: 18.762022018432617\n",
      "64: accuracy:0.7021276595744681 loss: 0.0003130439029518277 time: 19.055161237716675\n",
      "65: accuracy:0.7021276595744681 loss: 0.00043984337760272853 time: 19.343250036239624\n",
      "66: accuracy:0.7021276595744681 loss: 0.0002184361177810068 time: 19.626194953918457\n",
      "67: accuracy:0.7021276595744681 loss: 0.0005215285777897474 time: 19.909877061843872\n",
      "68: accuracy:0.7021276595744681 loss: 0.0003585847463347415 time: 20.195908069610596\n",
      "69: accuracy:0.7021276595744681 loss: 0.000293456636980251 time: 20.493690013885498\n",
      "70: accuracy:0.7021276595744681 loss: 0.0004954903862410375 time: 20.80134606361389\n",
      "71: accuracy:0.7021276595744681 loss: 0.00031695723756999886 time: 21.11912703514099\n",
      "72: accuracy:0.7021276595744681 loss: 0.00026732531187181966 time: 21.423660039901733\n",
      "73: accuracy:0.7021276595744681 loss: 0.00023313462453349943 time: 21.72401523590088\n",
      "74: accuracy:0.7021276595744681 loss: 0.000380680445995044 time: 22.032844066619873\n",
      "75: accuracy:0.7021276595744681 loss: 0.00034694749045008117 time: 22.319350004196167\n",
      "76: accuracy:0.7021276595744681 loss: 0.000254714552863154 time: 22.601150035858154\n",
      "77: accuracy:0.7021276595744681 loss: 0.00031423698173738455 time: 22.885042905807495\n",
      "78: accuracy:0.7021276595744681 loss: 0.00032207149293590477 time: 23.171292066574097\n",
      "79: accuracy:0.7021276595744681 loss: 0.0004131627300261366 time: 23.458799123764038\n",
      "80: accuracy:0.7021276595744681 loss: 0.00021212234761802356 time: 23.739988088607788\n",
      "81: accuracy:0.7021276595744681 loss: 0.00029906506932502505 time: 24.022912979125977\n",
      "82: accuracy:0.7021276595744681 loss: 0.00036233075568408476 time: 24.308470010757446\n",
      "83: accuracy:0.7021276595744681 loss: 0.0002862833643108433 time: 24.589652061462402\n",
      "84: accuracy:0.7021276595744681 loss: 0.00025880259471522393 time: 24.875471830368042\n",
      "85: accuracy:0.7021276595744681 loss: 0.0002589831594089098 time: 25.165187120437622\n",
      "86: accuracy:0.7021276595744681 loss: 0.00022148410990804177 time: 25.44877004623413\n",
      "87: accuracy:0.7021276595744681 loss: 0.00027027441570398126 time: 25.746619939804077\n",
      "88: accuracy:0.7021276595744681 loss: 0.0002072881383978193 time: 26.036388158798218\n",
      "89: accuracy:0.7021276595744681 loss: 0.0001874056439004893 time: 26.323275089263916\n",
      "90: accuracy:0.7021276595744681 loss: 0.0002695190519809186 time: 26.615257263183594\n",
      "91: accuracy:0.7021276595744681 loss: 0.0002962394216036327 time: 26.907673835754395\n",
      "92: accuracy:0.7021276595744681 loss: 0.00024406842294864007 time: 27.191771030426025\n",
      "93: accuracy:0.7021276595744681 loss: 0.00020732405279743864 time: 27.49945306777954\n",
      "94: accuracy:0.7021276595744681 loss: 0.0002791419821320267 time: 27.813741207122803\n",
      "95: accuracy:0.7021276595744681 loss: 0.00019427543282930822 time: 28.115648984909058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96: accuracy:0.7021276595744681 loss: 0.0001883964268220874 time: 28.471076250076294\n",
      "97: accuracy:0.7021276595744681 loss: 0.0001811087116305034 time: 28.921124935150146\n",
      "98: accuracy:0.7021276595744681 loss: 0.00022716222670937013 time: 29.247826099395752\n",
      "99: accuracy:0.7021276595744681 loss: 0.0001973300000059527 time: 29.53199601173401\n",
      "100: accuracy:0.7021276595744681 loss: 0.00022860916083633498 time: 29.883341073989868\n",
      "101: accuracy:0.7092198581560284 loss: 0.0002708420269908426 time: 30.20636796951294\n",
      "102: accuracy:0.7163120567375887 loss: 0.000194481080404937 time: 30.50254797935486\n",
      "103: accuracy:0.7163120567375887 loss: 0.0002449590042525683 time: 30.891391038894653\n",
      "104: accuracy:0.7163120567375887 loss: 0.00021264508716756225 time: 31.316843032836914\n",
      "105: accuracy:0.7163120567375887 loss: 0.00021373045159215817 time: 31.607234239578247\n",
      "106: accuracy:0.7163120567375887 loss: 0.00020558800173321298 time: 31.89966106414795\n",
      "107: accuracy:0.7163120567375887 loss: 0.00019838609927354614 time: 32.215559005737305\n",
      "108: accuracy:0.7163120567375887 loss: 0.00026594565100437656 time: 32.50928807258606\n",
      "109: accuracy:0.7163120567375887 loss: 0.0002011147006237327 time: 32.79560995101929\n",
      "110: accuracy:0.7163120567375887 loss: 0.00021907338117832203 time: 33.10283803939819\n",
      "111: accuracy:0.7163120567375887 loss: 0.0002576828448012642 time: 33.40646004676819\n",
      "112: accuracy:0.7163120567375887 loss: 0.0001914752057728286 time: 33.696341037750244\n",
      "113: accuracy:0.7163120567375887 loss: 0.00023056523648596895 time: 33.98042011260986\n",
      "114: accuracy:0.7163120567375887 loss: 0.00017350804386135265 time: 34.26235103607178\n",
      "115: accuracy:0.7163120567375887 loss: 0.00015472289002270553 time: 34.540400981903076\n",
      "116: accuracy:0.7163120567375887 loss: 0.00020767162893455497 time: 34.81528401374817\n",
      "117: accuracy:0.7163120567375887 loss: 0.00016255287538974477 time: 35.095526933670044\n",
      "118: accuracy:0.7163120567375887 loss: 0.00014854195422990505 time: 35.38144326210022\n",
      "119: accuracy:0.7163120567375887 loss: 0.00021166000503239753 time: 35.66096806526184\n",
      "120: accuracy:0.7163120567375887 loss: 0.00021944472111965803 time: 35.95519709587097\n",
      "121: accuracy:0.7163120567375887 loss: 0.00021473687144237173 time: 36.23926520347595\n",
      "122: accuracy:0.7163120567375887 loss: 0.00019617846790944375 time: 36.5363929271698\n",
      "123: accuracy:0.7163120567375887 loss: 0.0002384416938693893 time: 36.836642026901245\n",
      "124: accuracy:0.7163120567375887 loss: 0.00018135216073926128 time: 37.1343560218811\n",
      "125: accuracy:0.7163120567375887 loss: 0.00017161243872431596 time: 37.443751096725464\n",
      "126: accuracy:0.7163120567375887 loss: 0.0001742176034302442 time: 37.74139189720154\n",
      "127: accuracy:0.7163120567375887 loss: 0.00019467318363663365 time: 38.029447078704834\n",
      "128: accuracy:0.7163120567375887 loss: 0.00013604009166006442 time: 38.34701704978943\n",
      "129: accuracy:0.7163120567375887 loss: 0.0002119360040987926 time: 38.631558895111084\n",
      "130: accuracy:0.7163120567375887 loss: 0.0001821633945867112 time: 38.91447305679321\n",
      "131: accuracy:0.7163120567375887 loss: 9.832182696259803e-05 time: 39.203222036361694\n",
      "132: accuracy:0.7163120567375887 loss: 0.00014739845188464732 time: 39.49175190925598\n",
      "133: accuracy:0.7163120567375887 loss: 0.0001373618529427618 time: 39.77263402938843\n",
      "134: accuracy:0.7163120567375887 loss: 0.00017907430244097356 time: 40.06192708015442\n",
      "135: accuracy:0.7163120567375887 loss: 0.0002521068320545693 time: 40.348347902297974\n",
      "136: accuracy:0.7163120567375887 loss: 0.00013318818176095705 time: 40.63749313354492\n",
      "137: accuracy:0.7163120567375887 loss: 0.00018643697529306788 time: 40.930185079574585\n",
      "138: accuracy:0.7163120567375887 loss: 0.00015962591129030962 time: 41.2199330329895\n",
      "139: accuracy:0.7163120567375887 loss: 0.00016207376073533095 time: 41.51116919517517\n",
      "140: accuracy:0.7163120567375887 loss: 0.00013594883549340305 time: 41.80010390281677\n",
      "141: accuracy:0.7163120567375887 loss: 0.00012770023069563763 time: 42.085893869400024\n",
      "142: accuracy:0.7163120567375887 loss: 0.0001303261267419309 time: 42.36987495422363\n",
      "143: accuracy:0.7163120567375887 loss: 0.00011759197360330375 time: 42.654098987579346\n",
      "144: accuracy:0.7163120567375887 loss: 0.00010294722728964193 time: 42.94306421279907\n",
      "145: accuracy:0.7163120567375887 loss: 0.00018641285244317882 time: 43.22814607620239\n",
      "146: accuracy:0.7163120567375887 loss: 0.00015540611770356198 time: 43.515586137771606\n",
      "147: accuracy:0.7163120567375887 loss: 0.00018365130569903649 time: 43.80702805519104\n",
      "148: accuracy:0.7163120567375887 loss: 0.00010415088192853465 time: 44.09065508842468\n",
      "149: accuracy:0.7163120567375887 loss: 0.00017029128274491815 time: 44.37763524055481\n",
      "150: accuracy:0.7163120567375887 loss: 0.00016312107149277618 time: 44.67228126525879\n",
      "151: accuracy:0.7163120567375887 loss: 0.00016877064297852025 time: 44.955700159072876\n",
      "152: accuracy:0.7163120567375887 loss: 0.00014044575178257445 time: 45.2386200428009\n",
      "153: accuracy:0.7163120567375887 loss: 0.00015135302106622666 time: 45.52596688270569\n",
      "154: accuracy:0.7163120567375887 loss: 0.00010394387650101779 time: 45.813151121139526\n",
      "155: accuracy:0.7163120567375887 loss: 0.00011398052336937882 time: 46.09925103187561\n",
      "156: accuracy:0.7163120567375887 loss: 0.00011438839077874923 time: 46.39010691642761\n",
      "157: accuracy:0.7163120567375887 loss: 0.0001373798125120475 time: 46.68413805961609\n",
      "158: accuracy:0.7163120567375887 loss: 0.00011890431941592132 time: 46.98174214363098\n",
      "159: accuracy:0.7163120567375887 loss: 0.00013352261946476064 time: 47.269376039505005\n",
      "160: accuracy:0.7163120567375887 loss: 0.00010594455707200825 time: 47.560606956481934\n",
      "161: accuracy:0.7163120567375887 loss: 0.00010393716065357137 time: 47.84745812416077\n",
      "162: accuracy:0.7163120567375887 loss: 8.446198616751031e-05 time: 48.13430714607239\n",
      "163: accuracy:0.7163120567375887 loss: 0.00013254158439262348 time: 48.4440860748291\n",
      "164: accuracy:0.7163120567375887 loss: 0.00012269355580476164 time: 48.74412202835083\n",
      "165: accuracy:0.7163120567375887 loss: 0.0001122559853537248 time: 49.0803542137146\n",
      "166: accuracy:0.7163120567375887 loss: 0.00012275707953747375 time: 49.369773149490356\n",
      "167: accuracy:0.7163120567375887 loss: 0.00011390652823384885 time: 49.66138505935669\n",
      "168: accuracy:0.7163120567375887 loss: 0.00013114921723169002 time: 49.9447979927063\n",
      "169: accuracy:0.7163120567375887 loss: 0.00012682815084873614 time: 50.24293303489685\n",
      "170: accuracy:0.7163120567375887 loss: 0.00011247585360586295 time: 50.533777952194214\n",
      "171: accuracy:0.7163120567375887 loss: 0.0001124829276139851 time: 50.83220410346985\n",
      "172: accuracy:0.7163120567375887 loss: 0.00013549076387970872 time: 51.1209020614624\n",
      "173: accuracy:0.7163120567375887 loss: 0.00012405875537304972 time: 51.40593695640564\n",
      "174: accuracy:0.7163120567375887 loss: 8.061887922182923e-05 time: 51.740411043167114\n",
      "175: accuracy:0.7163120567375887 loss: 8.663715963885821e-05 time: 52.0452880859375\n",
      "176: accuracy:0.7163120567375887 loss: 0.00010995441647680642 time: 52.34410095214844\n",
      "177: accuracy:0.7163120567375887 loss: 0.00010995048128377149 time: 52.64619708061218\n",
      "178: accuracy:0.7163120567375887 loss: 9.642881695075545e-05 time: 52.981441020965576\n",
      "179: accuracy:0.7163120567375887 loss: 6.698546299794827e-05 time: 53.263487100601196\n",
      "180: accuracy:0.7163120567375887 loss: 0.000136414306823353 time: 53.5527241230011\n",
      "181: accuracy:0.7163120567375887 loss: 0.00010863858960453245 time: 53.84259796142578\n",
      "182: accuracy:0.7163120567375887 loss: 0.00011581867065049473 time: 54.1284339427948\n",
      "183: accuracy:0.7163120567375887 loss: 0.00010230218502757435 time: 54.419236183166504\n",
      "184: accuracy:0.7163120567375887 loss: 8.05867897032694e-05 time: 54.70620799064636\n",
      "185: accuracy:0.7163120567375887 loss: 7.615186446119994e-05 time: 54.984456062316895\n",
      "186: accuracy:0.7163120567375887 loss: 9.915376937953571e-05 time: 55.26795291900635\n",
      "187: accuracy:0.7163120567375887 loss: 0.0001071280236606853 time: 55.55597901344299\n",
      "188: accuracy:0.7163120567375887 loss: 0.00010141760728047242 time: 55.85242700576782\n",
      "189: accuracy:0.723404255319149 loss: 8.80451687740472e-05 time: 56.16056203842163\n",
      "190: accuracy:0.723404255319149 loss: 9.63710816405085e-05 time: 56.451472997665405\n",
      "191: accuracy:0.723404255319149 loss: 8.735586840328428e-05 time: 56.743186950683594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192: accuracy:0.723404255319149 loss: 8.529588208362629e-05 time: 57.028810024261475\n",
      "193: accuracy:0.723404255319149 loss: 0.00012417364087483458 time: 57.30850911140442\n",
      "194: accuracy:0.723404255319149 loss: 0.00011088207132253304 time: 57.59033703804016\n",
      "195: accuracy:0.723404255319149 loss: 9.454175043262276e-05 time: 57.88017010688782\n",
      "196: accuracy:0.723404255319149 loss: 0.00010105757025693812 time: 58.18093395233154\n",
      "197: accuracy:0.723404255319149 loss: 9.036079932600265e-05 time: 58.49079990386963\n",
      "198: accuracy:0.723404255319149 loss: 8.217502384552894e-05 time: 58.794337034225464\n",
      "199: accuracy:0.723404255319149 loss: 9.11660659559261e-05 time: 59.0922110080719\n",
      "200: accuracy:0.723404255319149 loss: 0.0001023885311365039 time: 59.40033316612244\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = CNN()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "start = time.time()\n",
    "for epoch in range(1,201): \n",
    "    for step, (batch_x, sen, batch_y,pos) in enumerate(loader):\n",
    "        pred = net(batch_x,pos)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_e,t_p)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss} time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
