{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function set_backend in module tensorly:\n",
      "\n",
      "set_backend(backend_name)\n",
      "    Sets the backend for TensorLy\n",
      "    \n",
      "        The backend will be set as specified and operations will used that backend\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    backend_name : {'mxnet', 'numpy', 'pytorch', 'tensorflow', 'cupy'}, default is 'numpy'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pytorch backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 128\n",
    "tl.set_backend('pytorch')\n",
    "help(tl.set_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(467,)\n"
     ]
    }
   ],
   "source": [
    "tag = [72, 71, 84, 54, 57, 65, 64]\n",
    "Y = np.zeros(467)\n",
    "print(Y.shape)\n",
    "Y[0 : tag[0]] = 0\n",
    "Y[tag[0] : tag[0]+tag[1]] = 1\n",
    "Y[tag[0]+tag[1] : tag[0]+tag[1]+tag[2]] = 2\n",
    "Y[tag[0]+tag[1]+tag[2] : tag[0]+tag[1]+tag[2]+tag[3]] = 3\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]] = 4\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]] = 5\n",
    "Y[tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5] : tag[0]+tag[1]+tag[2]+tag[3]+tag[4]+tag[5]+tag[6]] = 6\n",
    "Y = Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "MAX_LENGTH = 53\n",
    "for i in range(0,467):\n",
    "    a = np.loadtxt('/Users/denhiroshi/Downloads/Embeding/ans_1.0_'+str(i)+'.csv',dtype=np.float64,delimiter=',')\n",
    "    a = a.transpose(1,0)\n",
    "    a = np.exp(a)\n",
    "    a = np.sum(a,axis=1)\n",
    "    a = np.log(a)\n",
    "    if a.shape[0] < MAX_LENGTH:\n",
    "        add = MAX_LENGTH - a.shape[0]\n",
    "        adds = np.zeros(add).astype(np.float64)\n",
    "        a = np.concatenate((a, adds))\n",
    "    inputs.append(a)\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use = np.stack(inputs)\n",
    "mean = use.mean()         #计算平均数\n",
    "deviation = use.std()     #计算标准差\n",
    "# 标准化数据的公式: (数据值 - 平均数) / 标准差\n",
    "use = (use - mean) / deviation\n",
    "use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.fromfile('glove_WV.dat',dtype=np.float64).reshape((467,-1,200))\n",
    "position_tag = np.loadtxt('position_tag.csv',dtype=np.float64,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467, 53, 202)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [i for i in range(53)]\n",
    "c = []\n",
    "for i in range(467):\n",
    "    position_a = (np.array(temp) - position_tag[i][0]).reshape((-1,1))\n",
    "    position_b = (np.array(temp) - position_tag[i][1]).reshape((-1,1))\n",
    "    position = np.concatenate((position_a,position_b),axis = 1)\n",
    "    c.append(np.concatenate((b[i],position),axis = 1))\n",
    "c = np.stack(c)\n",
    "b = c\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "for i in range(467):\n",
    "    inputs.append((torch.from_numpy(b[i]),torch.from_numpy(use[i]),Y[i],position_tag[i].astype(np.int64)))\n",
    "shuffle(inputs)\n",
    "flag = int(len(inputs)*0.7)\n",
    "train = inputs[:flag]\n",
    "test = inputs[flag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([141, 53]),\n",
       " torch.Size([141, 53, 202]),\n",
       " torch.Size([141]),\n",
       " torch.Size([141, 2]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_s = []\n",
    "t_e = []\n",
    "t_y = []\n",
    "t_p = []\n",
    "\n",
    "for E,S,Y,pos in test:\n",
    "    t_s.append(S)\n",
    "    t_e.append(E)\n",
    "    t_y.append(Y)\n",
    "    t_p.append(pos)\n",
    "t_s = torch.stack(t_s)\n",
    "t_e = torch.stack(t_e)\n",
    "t_p = torch.from_numpy(np.stack(t_p))\n",
    "t_y = torch.from_numpy(np.array(t_y))\n",
    "t_s.shape, t_e.shape, t_y.shape, t_p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.8226950354609929 18轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 53, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=53,    # n_filters\n",
    "                kernel_size=(1,203),      # filter size\n",
    "            ),      # output shape (16, 53, 200)\n",
    "            nn.ReLU(),    # activation\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(53,1))   # 在 2x2 空间里向下采样, output shape (16, 53, 1)\n",
    "        self.output = nn.Linear(159, 7)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, sen, x, pos):\n",
    "        torch.set_default_dtype(torch.double)\n",
    "        sen = sen.reshape((sen.shape[0],1,sen.shape[1])) # (BATCH_SIZE,1,53)\n",
    "        use = torch.bmm(sen.double(),x) # (BATCH_SIZE,1,202)\n",
    "        use = torch.sigmoid(use) # (BATCH_SIZE,1,202)\n",
    "        use = torch.softmax(use,2) # (BATCH_SIZE,1,202)\n",
    "        use = use.reshape((use.shape[0],-1,1))\n",
    "        use = torch.bmm(x,use)\n",
    "        x = torch.cat((x,use),2)\n",
    "        \n",
    "        x = x.reshape((x.shape[0],1,x.shape[1],-1)).double()\n",
    "        x = self.conv1(x.double())\n",
    "        \n",
    "        x1 = torch.zeros(x.shape)\n",
    "        x2 = torch.zeros(x.shape)\n",
    "        x3 = torch.zeros(x.shape)\n",
    "        \n",
    "        min_x1 = torch.ones(x.shape) * (-100)\n",
    "        min_x2 = torch.ones(x.shape) * (-100)\n",
    "        min_x3 = torch.ones(x.shape) * (-100)\n",
    "        \n",
    "        for i in range(pos.shape[0]):\n",
    "            x1[i, :, :pos[i][0], :]\n",
    "            min_x1[i, :, :pos[i][0], :]  = 0.0\n",
    "            x2[i, :, pos[i][0]:pos[i][1], :]  = 1.0\n",
    "            min_x2[i, :, pos[i][0]:pos[i][1], :] = 0.0\n",
    "            x3[i, :, pos[i][1]:, :] = 1.0\n",
    "            min_x3[i, :, pos[i][1]:, :] = 0.0\n",
    "            \n",
    "         # 卷积结果*mask得到分段后的卷积向量\n",
    "        x1 *= x\n",
    "        x2 *= x\n",
    "        x3 *= x\n",
    "        \n",
    "        # 将无用部分赋予最小值，避免影响maxpool操作\n",
    "        x1 += min_x1\n",
    "        x2 += min_x2\n",
    "        x3 += min_x3\n",
    "        \n",
    "        # 分段池化\n",
    "        x1 = self.maxpool(x1)\n",
    "        x2 = self.maxpool(x2)\n",
    "        x3 = self.maxpool(x3)\n",
    "        \n",
    "        # 展平\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        \n",
    "        \n",
    "        x = torch.cat((x1,x2,x3),dim=1)\n",
    "\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 53, kernel_size=(1, 203), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=(53, 1), stride=(53, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (output): Linear(in_features=159, out_features=7, bias=True)\n",
      ")\n",
      "1: accuracy:0.2695035460992908 loss: 6.38185374282745 time: 0.31663012504577637\n",
      "2: accuracy:0.5106382978723404 loss: 5.435771316710462 time: 0.6906559467315674\n",
      "3: accuracy:0.6524822695035462 loss: 4.660417435807111 time: 1.0702130794525146\n",
      "4: accuracy:0.6312056737588653 loss: 3.441575977732122 time: 1.3829050064086914\n",
      "5: accuracy:0.7446808510638298 loss: 1.6585040217357736 time: 1.7395830154418945\n",
      "6: accuracy:0.6950354609929078 loss: 1.606130030754666 time: 2.053232192993164\n",
      "7: accuracy:0.7163120567375887 loss: 0.7283988401613254 time: 2.368453025817871\n",
      "8: accuracy:0.7304964539007093 loss: 1.7811122893831415 time: 2.690631866455078\n",
      "9: accuracy:0.7163120567375887 loss: 0.3371134581898572 time: 2.9972379207611084\n",
      "10: accuracy:0.7730496453900709 loss: 0.157797237475762 time: 3.311452865600586\n",
      "11: accuracy:0.7872340425531915 loss: 1.2728790850863443 time: 3.6207239627838135\n",
      "12: accuracy:0.8014184397163121 loss: 1.9347648328219857 time: 4.032065153121948\n",
      "13: accuracy:0.8226950354609929 loss: 0.05043482796406632 time: 4.355694055557251\n",
      "14: accuracy:0.7588652482269503 loss: 0.11402732256916465 time: 4.6698949337005615\n",
      "15: accuracy:0.7588652482269503 loss: 0.023499965244759287 time: 4.984930992126465\n",
      "16: accuracy:0.8014184397163121 loss: 0.01653548374785652 time: 5.293888092041016\n",
      "17: accuracy:0.8156028368794326 loss: 0.9897705309650937 time: 5.662079095840454\n",
      "18: accuracy:0.8226950354609929 loss: 0.005632057798094107 time: 5.977338075637817\n",
      "19: accuracy:0.8085106382978723 loss: 0.007457053336593476 time: 6.298821210861206\n",
      "20: accuracy:0.75177304964539 loss: 0.006275581847960986 time: 6.694589853286743\n",
      "21: accuracy:0.7659574468085106 loss: 0.04994339564035149 time: 7.010328054428101\n",
      "22: accuracy:0.7801418439716312 loss: 0.00709803298923773 time: 7.333957195281982\n",
      "23: accuracy:0.7730496453900709 loss: 0.010364647860224748 time: 7.684323072433472\n",
      "24: accuracy:0.8014184397163121 loss: 0.004991056714994421 time: 8.037408113479614\n",
      "25: accuracy:0.7872340425531915 loss: 0.00445193932671518 time: 8.379306077957153\n",
      "26: accuracy:0.7872340425531915 loss: 0.0031682838371492913 time: 8.692121028900146\n",
      "27: accuracy:0.8085106382978723 loss: 0.0041291709183285934 time: 9.018226861953735\n",
      "28: accuracy:0.8156028368794326 loss: 0.0035577239130057184 time: 9.324790954589844\n",
      "29: accuracy:0.8226950354609929 loss: 0.003850612677744718 time: 9.640032052993774\n",
      "30: accuracy:0.8085106382978723 loss: 0.0034264538866123255 time: 9.953216075897217\n",
      "31: accuracy:0.7943262411347518 loss: 0.0021146253113244187 time: 10.260502099990845\n",
      "32: accuracy:0.7943262411347518 loss: 0.0013844923897251718 time: 10.641511917114258\n",
      "33: accuracy:0.8014184397163121 loss: 0.0018521114187650869 time: 10.985234022140503\n",
      "34: accuracy:0.8085106382978723 loss: 0.0035050279003664706 time: 11.304752826690674\n",
      "35: accuracy:0.8085106382978723 loss: 0.0017755012217070083 time: 11.63358998298645\n",
      "36: accuracy:0.8085106382978723 loss: 0.0017019394163304113 time: 12.029783010482788\n",
      "37: accuracy:0.8156028368794326 loss: 0.0013749883985973417 time: 12.347212076187134\n",
      "38: accuracy:0.8156028368794326 loss: 0.0012538894459858912 time: 12.679841995239258\n",
      "39: accuracy:0.8156028368794326 loss: 0.0013272382506309974 time: 12.99176812171936\n",
      "40: accuracy:0.8085106382978723 loss: 0.0012227602937595933 time: 13.460059881210327\n",
      "41: accuracy:0.8085106382978723 loss: 0.0008839805966797724 time: 13.797722101211548\n",
      "42: accuracy:0.8085106382978723 loss: 0.0013545061749937939 time: 14.120323181152344\n",
      "43: accuracy:0.8085106382978723 loss: 0.001296398655459674 time: 14.444429159164429\n",
      "44: accuracy:0.8085106382978723 loss: 0.0015645064825690533 time: 14.752293825149536\n",
      "45: accuracy:0.8085106382978723 loss: 0.001042947487092689 time: 15.063647031784058\n",
      "46: accuracy:0.8085106382978723 loss: 0.0009553860350862348 time: 15.373711109161377\n",
      "47: accuracy:0.8085106382978723 loss: 0.0011500004594922762 time: 15.685519218444824\n",
      "48: accuracy:0.8085106382978723 loss: 0.000987720525924894 time: 15.999937057495117\n",
      "49: accuracy:0.8085106382978723 loss: 0.0011015313834779113 time: 16.31129503250122\n",
      "50: accuracy:0.8085106382978723 loss: 0.0007070802377460922 time: 16.62396001815796\n",
      "51: accuracy:0.8085106382978723 loss: 0.0008893551952923216 time: 16.93640398979187\n",
      "52: accuracy:0.8085106382978723 loss: 0.0008027392480219728 time: 17.254372119903564\n"
     ]
    }
   ],
   "source": [
    "# 创建数据加载器\n",
    "loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,      # mini batch size\n",
    "    shuffle = True,               # 设置随机洗牌\n",
    "    num_workers = 2,              # 加载数据的进程个数\n",
    ")\n",
    "net = CNN()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "loss_F = F.cross_entropy\n",
    "print(net)\n",
    "start = time.time()\n",
    "for epoch in range(1,201): \n",
    "    for step, (batch_x, sen, batch_y,pos) in enumerate(loader):\n",
    "        pred = net(sen,batch_x,pos)\n",
    "        loss = loss_F(pred,batch_y.long()) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0 and step == 2: # 每50步，计算精度\n",
    "            with torch.no_grad():\n",
    "                test_pred = net(t_s,t_e,t_p)\n",
    "                prob = torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls = torch.argmax(prob,dim=1)\n",
    "                acc = (pred_cls.int() == t_y.int()).sum().numpy() / pred_cls.size()[0]\n",
    "                print(f\"{epoch}: accuracy:{acc} loss: {loss} time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
